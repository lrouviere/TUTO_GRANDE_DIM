<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension</title>
  <meta name="description" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  
  
  

<meta name="author" content="Laurent Rouvière" />


<meta name="date" content="2020-08-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reg-comp.html"/>
<link rel="next" href="mod-add.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Régression en grande dimension<br> <br> L. Rouvière</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Présentation</a></li>
<li class="chapter" data-level="1" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html"><i class="fa fa-check"></i><b>1</b> Introduction à la grande dimension</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#fléau-de-la-dimension-pour-les-plus-proches-voisins"><i class="fa fa-check"></i><b>1.1</b> Fléau de la dimension pour les plus proches voisins</a></li>
<li class="chapter" data-level="1.2" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#influence-de-la-dimension-dans-le-modèle-linéaire"><i class="fa fa-check"></i><b>1.2</b> Influence de la dimension dans le modèle linéaire</a></li>
<li class="chapter" data-level="1.3" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#exercices"><i class="fa fa-check"></i><b>1.3</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reg-comp.html"><a href="reg-comp.html"><i class="fa fa-check"></i><b>2</b> Régression sur composantes</a><ul>
<li class="chapter" data-level="2.1" data-path="reg-comp.html"><a href="reg-comp.html#sélection-de-variables"><i class="fa fa-check"></i><b>2.1</b> Sélection de variables</a></li>
<li class="chapter" data-level="2.2" data-path="reg-comp.html"><a href="reg-comp.html#régression-sur-composantes-principales-méthodo"><i class="fa fa-check"></i><b>2.2</b> Régression sur composantes principales (méthodo)</a></li>
<li class="chapter" data-level="2.3" data-path="reg-comp.html"><a href="reg-comp.html#régression-pls-méthodo"><i class="fa fa-check"></i><b>2.3</b> Régression PLS : méthodo</a></li>
<li class="chapter" data-level="2.4" data-path="reg-comp.html"><a href="reg-comp.html#comparaison-pcr-vs-pls."><i class="fa fa-check"></i><b>2.4</b> Comparaison : PCR vs PLS.</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reg-pen.html"><a href="reg-pen.html"><i class="fa fa-check"></i><b>3</b> Régressions pénalisées (ou sous contraintes)</a><ul>
<li class="chapter" data-level="3.1" data-path="reg-pen.html"><a href="reg-pen.html#ridge-et-lasso-avec-glmnet"><i class="fa fa-check"></i><b>3.1</b> Ridge et lasso avec glmnet</a></li>
<li class="chapter" data-level="3.2" data-path="reg-pen.html"><a href="reg-pen.html#reconstruction-dun-signal"><i class="fa fa-check"></i><b>3.2</b> Reconstruction d’un signal</a></li>
<li class="chapter" data-level="3.3" data-path="reg-pen.html"><a href="reg-pen.html#régression-logistique-pénalisée"><i class="fa fa-check"></i><b>3.3</b> Régression logistique pénalisée</a></li>
<li class="chapter" data-level="3.4" data-path="reg-pen.html"><a href="reg-pen.html#exo-ridgelasso"><i class="fa fa-check"></i><b>3.4</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mod-add.html"><a href="mod-add.html"><i class="fa fa-check"></i><b>4</b> Modèle additif</a><ul>
<li class="chapter" data-level="4.1" data-path="mod-add.html"><a href="mod-add.html#pseudo-backfitting"><i class="fa fa-check"></i><b>4.1</b> Pseudo backfitting</a></li>
<li class="chapter" data-level="4.2" data-path="mod-add.html"><a href="mod-add.html#modèle-gam"><i class="fa fa-check"></i><b>4.2</b> Modèle GAM</a></li>
<li class="chapter" data-level="4.3" data-path="mod-add.html"><a href="mod-add.html#régression-logistique-additive"><i class="fa fa-check"></i><b>4.3</b> Régression logistique additive</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Régression en grande dimension</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg-pen" class="section level1">
<h1><span class="header-section-number">Chapitre 3</span> Régressions pénalisées (ou sous contraintes)</h1>
<p>Nous considérons toujours le modèle linéaire</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X_1+\dots+\beta_dX_d+\varepsilon\]</span>
Lorsque <span class="math inline">\(d\)</span> est grand ou que les variables sont linéairement dépendantes, les estimateurs des moindres carrées peuvent être mis en défaut. Les méthodes pénalisées ou sous contraintes consistent alors à restreindre l’espace sur lequel on minimise ce critère. On va alors chercher le vecteur <span class="math inline">\(\beta\)</span> qui minimise</p>
<p><span class="math display">\[\sum_{i=1}^n \left(y_i-\beta_0-\sum_{j=1}^dx_{ij}\beta_j\right)^2\quad\text{sous la contrainte }\quad\sum_{j=1}^d\beta_j^2\leq t\]</span>
ou de façon équivalente (dans le sens où il existe une équivalence entre <span class="math inline">\(t\)</span> et <span class="math inline">\(\lambda\)</span>)</p>
<p><span class="math display">\[\sum_{i=1}^n \left(y_i-\beta_0-\sum_{j=1}^dx_{ij}\beta_j\right)^2+\lambda\sum_{j=1}^d\beta_j^2.\]</span>
Les estimateurs obtenus sont les estimateurs <strong>ridge</strong>. Les estimateurs <strong>lasso</strong> s’obtiennent en remplaçant la contrainte ou la pénalité par une norme 1 (<span class="math inline">\(\sum_{j=1}^d|\beta_j|\)</span>). Nous présentons dans cette partie les étapes principales qui permettent de faire ce type de régression avec <strong>R</strong>. Le package le plus souvent utilisé est <code>glmnet</code>.</p>
<div id="ridge-et-lasso-avec-glmnet" class="section level2">
<h2><span class="header-section-number">3.1</span> Ridge et lasso avec glmnet</h2>
<p>On considère le jeu de données <code>ozone.txt</code> où on cherche à expliquer la concentration maximale en ozone relevée sur une journée (variable <code>maxO3</code>) par d’autres variables essentiellement météorologiques.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="reg-pen.html#cb56-1"></a>ozone &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ozone.txt&quot;</span>)</span>
<span id="cb56-2"><a href="reg-pen.html#cb56-2"></a><span class="kw">head</span>(ozone)</span>
<span id="cb56-3"><a href="reg-pen.html#cb56-3"></a>         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12</span>
<span id="cb56-4"><a href="reg-pen.html#cb56-4"></a><span class="dv">20010601</span>    <span class="dv">87</span> <span class="fl">15.6</span> <span class="fl">18.5</span> <span class="fl">18.4</span>   <span class="dv">4</span>    <span class="dv">4</span>    <span class="dv">8</span>  <span class="fl">0.6946</span> <span class="fl">-1.7101</span></span>
<span id="cb56-5"><a href="reg-pen.html#cb56-5"></a><span class="dv">20010602</span>    <span class="dv">82</span> <span class="fl">17.0</span> <span class="fl">18.4</span> <span class="fl">17.7</span>   <span class="dv">5</span>    <span class="dv">5</span>    <span class="dv">7</span> <span class="fl">-4.3301</span> <span class="fl">-4.0000</span></span>
<span id="cb56-6"><a href="reg-pen.html#cb56-6"></a><span class="dv">20010603</span>    <span class="dv">92</span> <span class="fl">15.3</span> <span class="fl">17.6</span> <span class="fl">19.5</span>   <span class="dv">2</span>    <span class="dv">5</span>    <span class="dv">4</span>  <span class="fl">2.9544</span>  <span class="fl">1.8794</span></span>
<span id="cb56-7"><a href="reg-pen.html#cb56-7"></a><span class="dv">20010604</span>   <span class="dv">114</span> <span class="fl">16.2</span> <span class="fl">19.7</span> <span class="fl">22.5</span>   <span class="dv">1</span>    <span class="dv">1</span>    <span class="dv">0</span>  <span class="fl">0.9848</span>  <span class="fl">0.3473</span></span>
<span id="cb56-8"><a href="reg-pen.html#cb56-8"></a><span class="dv">20010605</span>    <span class="dv">94</span> <span class="fl">17.4</span> <span class="fl">20.5</span> <span class="fl">20.4</span>   <span class="dv">8</span>    <span class="dv">8</span>    <span class="dv">7</span> <span class="fl">-0.5000</span> <span class="fl">-2.9544</span></span>
<span id="cb56-9"><a href="reg-pen.html#cb56-9"></a><span class="dv">20010606</span>    <span class="dv">80</span> <span class="fl">17.7</span> <span class="fl">19.8</span> <span class="fl">18.3</span>   <span class="dv">6</span>    <span class="dv">6</span>    <span class="dv">7</span> <span class="fl">-5.6382</span> <span class="fl">-5.0000</span></span>
<span id="cb56-10"><a href="reg-pen.html#cb56-10"></a>            Vx15 maxO3v  vent pluie</span>
<span id="cb56-11"><a href="reg-pen.html#cb56-11"></a><span class="dv">20010601</span> <span class="fl">-0.6946</span>     <span class="dv">84</span>  Nord   Sec</span>
<span id="cb56-12"><a href="reg-pen.html#cb56-12"></a><span class="dv">20010602</span> <span class="fl">-3.0000</span>     <span class="dv">87</span>  Nord   Sec</span>
<span id="cb56-13"><a href="reg-pen.html#cb56-13"></a><span class="dv">20010603</span>  <span class="fl">0.5209</span>     <span class="dv">82</span>   Est   Sec</span>
<span id="cb56-14"><a href="reg-pen.html#cb56-14"></a><span class="dv">20010604</span> <span class="fl">-0.1736</span>     <span class="dv">92</span>  Nord   Sec</span>
<span id="cb56-15"><a href="reg-pen.html#cb56-15"></a><span class="dv">20010605</span> <span class="fl">-4.3301</span>    <span class="dv">114</span> Ouest   Sec</span>
<span id="cb56-16"><a href="reg-pen.html#cb56-16"></a><span class="dv">20010606</span> <span class="fl">-6.0000</span>     <span class="dv">94</span> Ouest Pluie</span></code></pre></div>
<p>Contrairement à la plupart des autres package <strong>R</strong> qui permettent de faire de l’apprentissage, le package <code>glmnet</code> n’autorise pas l’utilisation de <code>formules</code> : il faut spécifier explicitement la matrice des <span class="math inline">\(X\)</span> et le vecteur des <span class="math inline">\(Y\)</span>. On peut obtenir la matrice des <span class="math inline">\(X\)</span> et notamment le codage des variables qualitatives avec la fonction <code>model.matrix</code>:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="reg-pen.html#cb57-1"></a>ozone.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(maxO3<span class="op">~</span>.,<span class="dt">data=</span>ozone)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb57-2"><a href="reg-pen.html#cb57-2"></a>ozone.Y &lt;-<span class="st"> </span>ozone<span class="op">$</span>maxO3</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Charger le package <code>glmnet</code> et à l’aide de la fonction <code>glmnet</code> calculer les estimateurs <code>ridge</code> et <code>lasso</code>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="reg-pen.html#cb58-1"></a><span class="kw">library</span>(glmnet)</span>
<span id="cb58-2"><a href="reg-pen.html#cb58-2"></a>mod.R &lt;-<span class="st"> </span><span class="kw">glmnet</span>(ozone.X,ozone.Y,<span class="dt">alpha=</span><span class="dv">0</span>)</span>
<span id="cb58-3"><a href="reg-pen.html#cb58-3"></a>mod.L &lt;-<span class="st"> </span><span class="kw">glmnet</span>(ozone.X,ozone.Y,<span class="dt">alpha=</span><span class="dv">1</span>)</span></code></pre></div></li>
<li><p>Analyser les sorties qui se trouvent dans les arguments <code>lambda</code> et <code>beta</code> de <code>glmnet</code>.</p>
<div class="corR">
<p>
La fonction <code>glmnet</code> calcule tous les estimateurs pour une grille de valeurs de <code>lambda</code> spécifiée ici :
</p>
</div>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="reg-pen.html#cb59-1"></a>mod.R<span class="op">$</span>lambda <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</span>
<span id="cb59-2"><a href="reg-pen.html#cb59-2"></a>[<span class="dv">1</span>] <span class="fl">22007.27</span> <span class="fl">20052.20</span> <span class="fl">18270.82</span> <span class="fl">16647.69</span> <span class="fl">15168.76</span> <span class="fl">13821.21</span></span></code></pre></div>
<div class="corR">
<p>
On peut récupérer les valeurs de <code>beta</code> associées à chaque valeur de la grille avec
</p>
</div>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="reg-pen.html#cb60-1"></a>mod.R<span class="op">$</span>beta[,<span class="dv">1</span>]</span>
<span id="cb60-2"><a href="reg-pen.html#cb60-2"></a>           T9           T12           T15           Ne9 </span>
<span id="cb60-3"><a href="reg-pen.html#cb60-3"></a> <span class="fl">6.376767e-36</span>  <span class="fl">5.523924e-36</span>  <span class="fl">4.867402e-36</span> <span class="fl">-6.821464e-36</span> </span>
<span id="cb60-4"><a href="reg-pen.html#cb60-4"></a>         Ne12          Ne15           Vx9          Vx12 </span>
<span id="cb60-5"><a href="reg-pen.html#cb60-5"></a><span class="fl">-7.994984e-36</span> <span class="fl">-5.839057e-36</span>  <span class="fl">5.706014e-36</span>  <span class="fl">4.387350e-36</span> </span>
<span id="cb60-6"><a href="reg-pen.html#cb60-6"></a>         Vx15        maxO3v      ventNord     ventOuest </span>
<span id="cb60-7"><a href="reg-pen.html#cb60-7"></a> <span class="fl">3.970583e-36</span>  <span class="fl">6.892387e-37</span> <span class="fl">-5.830507e-36</span> <span class="fl">-1.022483e-35</span> </span>
<span id="cb60-8"><a href="reg-pen.html#cb60-8"></a>      ventSud      pluieSec </span>
<span id="cb60-9"><a href="reg-pen.html#cb60-9"></a> <span class="fl">1.519222e-35</span>  <span class="fl">2.772246e-35</span> </span></code></pre></div></li>
<li><p>Visualiser les chemins de régularisation des estimateurs <code>ridge</code> et <code>lasso</code>. On pourra utiliser la fonction <code>plot</code>.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="reg-pen.html#cb61-1"></a><span class="kw">plot</span>(mod.R,<span class="dt">label=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-96-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="reg-pen.html#cb62-1"></a><span class="kw">plot</span>(mod.L,<span class="dt">label=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-96-2.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="reg-pen.html#cb63-1"></a><span class="kw">plot</span>(mod.R,<span class="dt">xvar=</span><span class="st">&quot;lambda&quot;</span>,<span class="dt">label=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-96-3.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="reg-pen.html#cb64-1"></a><span class="kw">plot</span>(mod.L,<span class="dt">xvar=</span><span class="st">&quot;lambda&quot;</span>,<span class="dt">label=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-96-4.png" width="672" style="display: block; margin: auto;" /></p></li>
<li><p>Sélectionner les paramètres de régularisation à l’aide de la fonction <code>cv.glmnet</code>. On pourra notamment faire un <code>plot</code> de l’objet et expliquer le graphe obtenu.</p>
<div class="corR">
<p>
Commençons par <strong>ridge</strong> :
</p>
</div>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="reg-pen.html#cb65-1"></a>ridgeCV &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(ozone.X,ozone.Y,<span class="dt">alpha=</span><span class="dv">0</span>)</span>
<span id="cb65-2"><a href="reg-pen.html#cb65-2"></a><span class="kw">plot</span>(ridgeCV)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-98-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
<p>On visualise les erreurs quadratiques calculées par validation croisée 10 blocs en fonction de <code>lambda</code> (échelle logarithmique). Deux traites verticaux sont représentés :</p>
</p>
<ul>
<li>
<p>celui de gauche correspond à la valeur de <code>lambda</code> qui minimise l’erreur quadratique ;</p>
</li>
<li>
<p>celui de droite correspond à la plus grande valeur de <code>lambda</code> telle que l’erreur ne dépasse pas l’erreur minimale + 1 écart-type estimé de cette erreur.</p>
</li>
</ul>
<p>
<p>D’un point de vu pratique, cela signifie que l’utilisateur peut choisir n’importe quelle valeur de <code>lambda</code> entre les deux traits verticaux. Si on veut diminuer la complexité du modèle on choisir la valeur de droite. On peut obtenir ces deux valeurs avec</p>
</p>
</div>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="reg-pen.html#cb66-1"></a> ridgeCV<span class="op">$</span>lambda.min</span>
<span id="cb66-2"><a href="reg-pen.html#cb66-2"></a> [<span class="dv">1</span>] <span class="fl">10.70126</span></span>
<span id="cb66-3"><a href="reg-pen.html#cb66-3"></a> ridgeCV<span class="op">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb66-4"><a href="reg-pen.html#cb66-4"></a> [<span class="dv">1</span>] <span class="fl">47.41322</span></span></code></pre></div>
<div class="corR">
<p>
On peut faire de même pour le <strong>lasso</strong> :
</p>
</div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="reg-pen.html#cb67-1"></a> lassoCV &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(ozone.X,ozone.Y,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb67-2"><a href="reg-pen.html#cb67-2"></a> <span class="kw">plot</span>(lassoCV)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-102-1.png" width="672" style="display: block; margin: auto;" /></p></li>
<li><p>On souhaite prédire la variable cible pour de nouveaux individus. Prenons par exemple les 25ème et 50ème individus du jeu de données. Calculer les valeurs prédites.</p>
<div class="corR">
<p>
Une première approche pourrait consister à réajuster le modèle sur toutes les données pour la valeur de <code>lambda</code> sélectionnée. Cette étape est en réalité déjà effectuée par la fonction <code>cv.glmnet</code>. Il suffit par conséquent d’appliquer la fonction <code>predict</code> à l’objet obtenu avec <code>cv.glmnet</code> en spécifiant la valeur de <code>lambda</code> souhaitée. Par exemple pour <strong>ridge</strong> :
</p>
</div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="reg-pen.html#cb68-1"></a><span class="kw">predict</span>(ridgeCV,<span class="dt">newx =</span> ozone.X[<span class="dv">50</span><span class="op">:</span><span class="dv">51</span>,],<span class="dt">s=</span><span class="st">&quot;lambda.min&quot;</span>)</span>
<span id="cb68-2"><a href="reg-pen.html#cb68-2"></a>                <span class="dv">1</span></span>
<span id="cb68-3"><a href="reg-pen.html#cb68-3"></a><span class="dv">20010723</span> <span class="fl">90.34787</span></span>
<span id="cb68-4"><a href="reg-pen.html#cb68-4"></a><span class="dv">20010724</span> <span class="fl">96.71932</span></span>
<span id="cb68-5"><a href="reg-pen.html#cb68-5"></a><span class="kw">predict</span>(ridgeCV,<span class="dt">newx =</span> ozone.X[<span class="dv">50</span><span class="op">:</span><span class="dv">51</span>,],<span class="dt">s=</span><span class="st">&quot;lambda.1se&quot;</span>)</span>
<span id="cb68-6"><a href="reg-pen.html#cb68-6"></a>                <span class="dv">1</span></span>
<span id="cb68-7"><a href="reg-pen.html#cb68-7"></a><span class="dv">20010723</span> <span class="fl">93.33611</span></span>
<span id="cb68-8"><a href="reg-pen.html#cb68-8"></a><span class="dv">20010724</span> <span class="fl">96.14918</span></span></code></pre></div>
<div class="corR">
<p>
On peut faire de même pour le <strong>lasso</strong> :
</p>
</div>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="reg-pen.html#cb69-1"></a><span class="kw">predict</span>(lassoCV,<span class="dt">newx =</span> ozone.X[<span class="dv">50</span><span class="op">:</span><span class="dv">51</span>,],<span class="dt">s=</span><span class="st">&quot;lambda.min&quot;</span>)</span>
<span id="cb69-2"><a href="reg-pen.html#cb69-2"></a>                <span class="dv">1</span></span>
<span id="cb69-3"><a href="reg-pen.html#cb69-3"></a><span class="dv">20010723</span> <span class="fl">87.19995</span></span>
<span id="cb69-4"><a href="reg-pen.html#cb69-4"></a><span class="dv">20010724</span> <span class="fl">97.82825</span></span>
<span id="cb69-5"><a href="reg-pen.html#cb69-5"></a><span class="kw">predict</span>(lassoCV,<span class="dt">newx =</span> ozone.X[<span class="dv">50</span><span class="op">:</span><span class="dv">51</span>,],<span class="dt">s=</span><span class="st">&quot;lambda.1se&quot;</span>)</span>
<span id="cb69-6"><a href="reg-pen.html#cb69-6"></a>                <span class="dv">1</span></span>
<span id="cb69-7"><a href="reg-pen.html#cb69-7"></a><span class="dv">20010723</span> <span class="fl">87.40631</span></span>
<span id="cb69-8"><a href="reg-pen.html#cb69-8"></a><span class="dv">20010724</span> <span class="fl">95.85602</span></span></code></pre></div></li>
<li><p>A l’aide d’une validation croisée, comparer les performances des estimateurs <strong>MCO</strong>, <strong>ridge</strong> et <strong>lasso</strong>. On pourra utiliser les données <code>ozone_complet.txt</code> qui contiennent plus d’individus et de variables.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="reg-pen.html#cb70-1"></a>ozone1 &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ozone_complet.txt&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;;&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">na.omit</span>()</span>
<span id="cb70-2"><a href="reg-pen.html#cb70-2"></a>ozone1.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(maxO3<span class="op">~</span>.,<span class="dt">data=</span>ozone1)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb70-3"><a href="reg-pen.html#cb70-3"></a>ozone1.Y &lt;-<span class="st"> </span>ozone1<span class="op">$</span>maxO3</span></code></pre></div>
<div class="corR">
<p>
On crée une fonction qui calcule les erreurs quadratiques par validations croisée des 3 procédures d’estimation.
</p>
</div>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="reg-pen.html#cb71-1"></a>cv.ridge.lasso &lt;-<span class="st"> </span><span class="cf">function</span>(data,form){</span>
<span id="cb71-2"><a href="reg-pen.html#cb71-2"></a>  <span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb71-3"><a href="reg-pen.html#cb71-3"></a>  data.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(form,<span class="dt">data=</span>data)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb71-4"><a href="reg-pen.html#cb71-4"></a>  data.Y &lt;-<span class="st"> </span>data<span class="op">$</span>maxO3</span>
<span id="cb71-5"><a href="reg-pen.html#cb71-5"></a>  blocs &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">createFolds</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data),<span class="dt">k=</span><span class="dv">10</span>)</span>
<span id="cb71-6"><a href="reg-pen.html#cb71-6"></a>  prev &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">ncol=</span><span class="dv">3</span>,<span class="dt">nrow=</span><span class="kw">nrow</span>(data)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb71-7"><a href="reg-pen.html#cb71-7"></a>  <span class="kw">names</span>(prev) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lin&quot;</span>,<span class="st">&quot;ridge&quot;</span>,<span class="st">&quot;lasso&quot;</span>)</span>
<span id="cb71-8"><a href="reg-pen.html#cb71-8"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){</span>
<span id="cb71-9"><a href="reg-pen.html#cb71-9"></a>app &lt;-<span class="st"> </span>data[<span class="op">-</span>blocs[[k]],]</span>
<span id="cb71-10"><a href="reg-pen.html#cb71-10"></a>test &lt;-<span class="st"> </span>data[blocs[[k]],]</span>
<span id="cb71-11"><a href="reg-pen.html#cb71-11"></a>app.X &lt;-<span class="st"> </span>data.X[<span class="op">-</span>blocs[[k]],]</span>
<span id="cb71-12"><a href="reg-pen.html#cb71-12"></a>app.Y &lt;-<span class="st"> </span>data.Y[<span class="op">-</span>blocs[[k]]]</span>
<span id="cb71-13"><a href="reg-pen.html#cb71-13"></a>test.X &lt;-<span class="st"> </span>data.X[blocs[[k]],]</span>
<span id="cb71-14"><a href="reg-pen.html#cb71-14"></a>test.Y &lt;-<span class="st"> </span>data.Y[blocs[[k]]]</span>
<span id="cb71-15"><a href="reg-pen.html#cb71-15"></a>ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(app.X,app.Y,<span class="dt">alpha=</span><span class="dv">0</span>)</span>
<span id="cb71-16"><a href="reg-pen.html#cb71-16"></a>lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(app.X,app.Y,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb71-17"><a href="reg-pen.html#cb71-17"></a>lin &lt;-<span class="st"> </span><span class="kw">lm</span>(form,<span class="dt">data=</span>app)</span>
<span id="cb71-18"><a href="reg-pen.html#cb71-18"></a>prev[blocs[[k]],] &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">lin=</span><span class="kw">predict</span>(lin,<span class="dt">newdata=</span>test),</span>
<span id="cb71-19"><a href="reg-pen.html#cb71-19"></a>           <span class="dt">ridge=</span><span class="kw">as.vector</span>(<span class="kw">predict</span>(ridge,<span class="dt">newx=</span>test.X)),</span>
<span id="cb71-20"><a href="reg-pen.html#cb71-20"></a>           <span class="dt">lasso=</span><span class="kw">as.vector</span>(<span class="kw">predict</span>(lasso,<span class="dt">newx=</span>test.X)))</span>
<span id="cb71-21"><a href="reg-pen.html#cb71-21"></a>  }</span>
<span id="cb71-22"><a href="reg-pen.html#cb71-22"></a>  err &lt;-<span class="st"> </span>prev <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">obs=</span>data<span class="op">$</span>maxO3) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise_at</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="op">~</span><span class="kw">mean</span>((obs<span class="op">-</span>.)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb71-23"><a href="reg-pen.html#cb71-23"></a>  <span class="kw">return</span>(err)</span>
<span id="cb71-24"><a href="reg-pen.html#cb71-24"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="reg-pen.html#cb72-1"></a><span class="kw">cv.ridge.lasso</span>(ozone1,<span class="dt">form=</span><span class="kw">formula</span>(maxO3<span class="op">~</span>.))</span>
<span id="cb72-2"><a href="reg-pen.html#cb72-2"></a>       lin    ridge    lasso</span>
<span id="cb72-3"><a href="reg-pen.html#cb72-3"></a><span class="dv">1</span> <span class="fl">184.3755</span> <span class="fl">192.4984</span> <span class="fl">191.5436</span></span></code></pre></div>
<div class="corR">
<p>
On remarque que les approches régularisées n’apportent rien par rapport aux estimateurs MCO ici. Ceci peut s’expliquer par le fait que le nombre de variables n’est pas très important.
</p>
</div></li>
<li><p>Refaire la question précédente en considérant toutes les interactions d’ordre 2.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="reg-pen.html#cb73-1"></a><span class="kw">cv.ridge.lasso</span>(ozone1,<span class="dt">form=</span><span class="kw">formula</span>(maxO3<span class="op">~</span>.<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb73-2"><a href="reg-pen.html#cb73-2"></a>       lin    ridge    lasso</span>
<span id="cb73-3"><a href="reg-pen.html#cb73-3"></a><span class="dv">1</span> <span class="fl">185.0517</span> <span class="fl">168.7122</span> <span class="fl">166.0982</span></span></code></pre></div>
<div class="corR">
<p>
Les méthodes régularisées permettent ici de diminuer les erreurs quadratiques de manière intéressante. Cela vient certainement du fait du nombre de variables explicatives qui est beaucoup plus important lorsqu’on prend en compte toutes les interactions d’ordre 2, nous en avons en effet 253 :
</p>
</div>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="reg-pen.html#cb74-1"></a>ozone2.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(maxO3<span class="op">~</span>.<span class="op">^</span><span class="dv">2</span>,<span class="dt">data=</span>ozone1)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb74-2"><a href="reg-pen.html#cb74-2"></a><span class="kw">dim</span>(ozone2.X)</span>
<span id="cb74-3"><a href="reg-pen.html#cb74-3"></a>[<span class="dv">1</span>] <span class="dv">1366</span>  <span class="dv">253</span></span></code></pre></div></li>
</ol>
</div>
<div id="reconstruction-dun-signal" class="section level2">
<h2><span class="header-section-number">3.2</span> Reconstruction d’un signal</h2>
<p>Le fichier <code>signal.csv</code> contient un signal que l’on peut représenter par une fonction <span class="math inline">\(m:\mathbb R\to\mathbb R\)</span>. On le visualise</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="reg-pen.html#cb75-1"></a>signal &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/signal.csv&quot;</span>)</span>
<span id="cb75-2"><a href="reg-pen.html#cb75-2"></a><span class="kw">ggplot</span>(signal)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>()</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-113-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Plaçons nous dans le cas où on ne dispose que d’une version bruitée de ce signal. La courbe n’est pas observée mais on dispose d’un échantillon <span class="math inline">\((x_i,y_i),i=1,\dots,n\)</span> généré selon le modèle</p>
<p><span class="math display">\[y_i=m(x_i)+\varepsilon_i.\]</span></p>
<p>Le fichier <code>ech_signal.csv</code> contient <span class="math inline">\(n=60\)</span> observations issues de ce modèle. On représente les données et la courbe</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="reg-pen.html#cb76-1"></a>donnees &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/ech_signal.csv&quot;</span>)</span>
<span id="cb76-2"><a href="reg-pen.html#cb76-2"></a><span class="kw">ggplot</span>(signal)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>()<span class="op">+</span></span>
<span id="cb76-3"><a href="reg-pen.html#cb76-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>donnees,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-114-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Nous cherchons dans cette partie à reconstruire le signal à partir de l’échantillon. Bien entendu, vu la forme du signal, un modèle linéaire de la forme
<span class="math display">\[y_i=\beta_0+\beta_1x_i+\varepsilon_i\]</span>
n’est pas approprié. De nombreuses approches en <strong>traitement du signal</strong> proposent d’utiliser une <code>base</code> ou <code>dictionnaire</code> représentée par une collection de fonctions <span class="math inline">\(\{\psi_j(x)\}_{j=1,\dots,K}\)</span> et de décomposer le signal dans cette base :</p>
<p><span class="math display">\[m(x)\approx \sum_{j=1}^K \beta_j\psi_j(x).\]</span></p>
<p>Pour un dictionnaire donné, on peut alors considérer un <strong>modèle linéaire</strong></p>
<p><span class="math display" id="eq:mod-lin-signal">\[\begin{equation}
  y_i=\sum_{j=1}^K \beta_j\psi_j(x)+\varepsilon_i.
  \tag{3.1}
\end{equation}\]</span></p>
<p>Le problème est toujours d’estimer les paramètres <span class="math inline">\(\beta_j\)</span> mais les variables sont maintenant définies par les élements du dictionnaire. Il existe différent type de dictionnaire, dans cet exercice nous proposons de considérer la base de Fourier définie par</p>
<p><span class="math display">\[\psi_0(x)=1,\quad \psi_{2j-1}(x)=\cos(2j\pi x)\quad\text{et}\quad \psi_{2j}(x)=\sin(2j\pi x),\quad j=1,\dots,K.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Écrire une fonction <strong>R</strong> qui admet en entrée :</p>
<ul>
<li>une grille de valeurs de <code>x</code> (un vecteur)</li>
<li>une valeur de <code>K</code> (un entier positif)</li>
</ul>
<p>et qui renvoie en sortie une matrice qui contiennent les valeurs du dictionnaire pour chaque valeur de <code>x</code>. Cette matrice devra donc contenir <code>2K</code> colonnes et le nombre de lignes sera égal à la longueur du vecteur <code>x</code>.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="reg-pen.html#cb77-1"></a>mat.dict &lt;-<span class="st"> </span><span class="cf">function</span>(K,x){</span>
<span id="cb77-2"><a href="reg-pen.html#cb77-2"></a>	res &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span><span class="kw">length</span>(x),<span class="dt">ncol=</span><span class="dv">2</span><span class="op">*</span>K) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>()</span>
<span id="cb77-3"><a href="reg-pen.html#cb77-3"></a>	<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K){</span>
<span id="cb77-4"><a href="reg-pen.html#cb77-4"></a>	  res[,<span class="dv">2</span><span class="op">*</span>j<span class="dv">-1</span>] &lt;-<span class="st"> </span><span class="kw">cos</span>(<span class="dv">2</span><span class="op">*</span>j<span class="op">*</span>pi<span class="op">*</span>x)</span>
<span id="cb77-5"><a href="reg-pen.html#cb77-5"></a>		res[,<span class="dv">2</span><span class="op">*</span>j] &lt;-<span class="st"> </span><span class="kw">sin</span>(<span class="dv">2</span><span class="op">*</span>j<span class="op">*</span>pi<span class="op">*</span>x)</span>
<span id="cb77-6"><a href="reg-pen.html#cb77-6"></a>	}</span>
<span id="cb77-7"><a href="reg-pen.html#cb77-7"></a>	<span class="kw">return</span>(res)</span>
<span id="cb77-8"><a href="reg-pen.html#cb77-8"></a>}</span></code></pre></div></li>
<li><p>On fixe <code>K=25</code>. Calculer les estimateurs des moindres carrés du modèle <a href="reg-pen.html#eq:mod-lin-signal">(3.1)</a>.</p>
<div class="corR">
<p>
Il suffit d’ajuster le modèle linéaire où les variables explicatives sont données par le dictionnaire :
</p>
</div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="reg-pen.html#cb78-1"></a>D25 &lt;-<span class="st"> </span><span class="kw">mat.dict</span>(<span class="dv">25</span>,donnees<span class="op">$</span>X) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Y=</span>donnees<span class="op">$</span>Y)</span>
<span id="cb78-2"><a href="reg-pen.html#cb78-2"></a>mod.lin &lt;-<span class="st"> </span><span class="kw">lm</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>D25)</span></code></pre></div></li>
<li><p>Représenter le signal estimé. Commenter le graphe.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="reg-pen.html#cb79-1"></a>S25 &lt;-<span class="st"> </span><span class="kw">mat.dict</span>(<span class="dv">25</span>,signal<span class="op">$</span>x)</span>
<span id="cb79-2"><a href="reg-pen.html#cb79-2"></a>prev.MCO &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.lin,<span class="dt">newdata =</span> S25)</span>
<span id="cb79-3"><a href="reg-pen.html#cb79-3"></a>signal1 &lt;-<span class="st"> </span>signal <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">MCO=</span>prev.MCO) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(<span class="dt">signal=</span>y)</span>
<span id="cb79-4"><a href="reg-pen.html#cb79-4"></a>signal2 &lt;-<span class="st"> </span>signal1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="op">-</span>x,<span class="dt">names_to=</span><span class="st">&quot;meth&quot;</span>,<span class="dt">values_to=</span><span class="st">&quot;y&quot;</span>)</span>
<span id="cb79-5"><a href="reg-pen.html#cb79-5"></a><span class="kw">ggplot</span>(signal2)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>meth))<span class="op">+</span></span>
<span id="cb79-6"><a href="reg-pen.html#cb79-6"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>))<span class="op">+</span><span class="kw">geom_point</span>(<span class="dt">data=</span>donnees,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-118-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
Le signal estimé a tendance à surajuster les données. Cela vient du fait que on estime 51 paramètres avec seulement 60 observations.
</p>
</div></li>
<li><p>Calculer les estimateurs <strong>lasso</strong> et représenter le signal issu de ces estimateurs.</p>
<div class="corR">
<p>
On regarde tout d’abord le <code>chemin de régularisation</code> des estimateurs <strong>lasso</strong>
</p>
</div>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="reg-pen.html#cb80-1"></a>X<span class="fl">.25</span> &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>D25)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb80-2"><a href="reg-pen.html#cb80-2"></a>lasso1 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(X<span class="fl">.25</span>,D25<span class="op">$</span>Y,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb80-3"><a href="reg-pen.html#cb80-3"></a><span class="kw">plot</span>(lasso1)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-121-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
Il semble que quelques coefficients quittent la valeur 0 bien avant les autres. On effectue maintenant la validation croisée pour sélectionner le paramètre <span class="math inline"><span class="math inline">\(\lambda\)</span></span>.
</p>
</div>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="reg-pen.html#cb81-1"></a>lasso.cv &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(X<span class="fl">.25</span>,D25<span class="op">$</span>Y,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb81-2"><a href="reg-pen.html#cb81-2"></a><span class="kw">plot</span>(lasso.cv)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-123-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
On calcule les prévisions et on trace le signal.
</p>
</div>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="reg-pen.html#cb82-1"></a>prev.lasso &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">predict</span>(lasso.cv,<span class="dt">newx=</span><span class="kw">as.matrix</span>(S25)))</span>
<span id="cb82-2"><a href="reg-pen.html#cb82-2"></a>signal1<span class="op">$</span>lasso &lt;-<span class="st"> </span>prev.lasso</span>
<span id="cb82-3"><a href="reg-pen.html#cb82-3"></a>signal2 &lt;-<span class="st"> </span>signal1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="op">-</span>x,<span class="dt">names_to=</span><span class="st">&quot;meth&quot;</span>,<span class="dt">values_to=</span><span class="st">&quot;y&quot;</span>)</span>
<span id="cb82-4"><a href="reg-pen.html#cb82-4"></a><span class="kw">ggplot</span>(signal2)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>meth))<span class="op">+</span></span>
<span id="cb82-5"><a href="reg-pen.html#cb82-5"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>))<span class="op">+</span><span class="kw">geom_point</span>(<span class="dt">data=</span>donnees,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-125-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
L’algorithme <strong>lasso</strong> a permi de corriger le problème de sur-apprentissage.
</p>
</div></li>
<li><p>Identifier les coefficients lasso sélectionnés qui ne sont pas nuls.</p></li>
</ol>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="reg-pen.html#cb83-1"></a>v.sel &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">coef</span>(lasso.cv)<span class="op">!=</span><span class="dv">0</span>)</span>
<span id="cb83-2"><a href="reg-pen.html#cb83-2"></a>v.sel</span>
<span id="cb83-3"><a href="reg-pen.html#cb83-3"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">8</span> <span class="dv">21</span> <span class="dv">28</span> <span class="dv">30</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">40</span></span></code></pre></div>
<ol start="6" style="list-style-type: decimal">
<li><p>Ajouter les signaux ajustés par les algorithme PCR et PLS.</p>
<div class="corR">
<ul>
<li>
<p>On effectue la <code>PCR</code> :</p>
</li>
</ul>
</div>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="reg-pen.html#cb84-1"></a> pcr.fit &lt;-<span class="st"> </span><span class="kw">pcr</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>D25,<span class="dt">validation=</span><span class="st">&quot;CV&quot;</span>)</span>
<span id="cb84-2"><a href="reg-pen.html#cb84-2"></a> ncomp.pcr &lt;-<span class="st"> </span><span class="kw">which.min</span>(pcr.fit<span class="op">$</span>validation<span class="op">$</span>PRESS)</span>
<span id="cb84-3"><a href="reg-pen.html#cb84-3"></a> ncomp.pcr</span>
<span id="cb84-4"><a href="reg-pen.html#cb84-4"></a> [<span class="dv">1</span>] <span class="dv">33</span></span>
<span id="cb84-5"><a href="reg-pen.html#cb84-5"></a> prev.pcr &lt;-<span class="st"> </span><span class="kw">predict</span>(pcr.fit,<span class="dt">newdata=</span>S25,<span class="dt">ncomp=</span>ncomp.pcr)</span></code></pre></div>
<div class="corR">
<ul>
<li>
<p>Puis la <code>PLS</code> :</p>
</li>
</ul>
</div>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="reg-pen.html#cb85-1"></a> pls.fit &lt;-<span class="st"> </span><span class="kw">plsr</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>D25,<span class="dt">validation=</span><span class="st">&quot;CV&quot;</span>)</span>
<span id="cb85-2"><a href="reg-pen.html#cb85-2"></a> ncomp.pls &lt;-<span class="st"> </span><span class="kw">which.min</span>(pls.fit<span class="op">$</span>validation<span class="op">$</span>PRESS)</span>
<span id="cb85-3"><a href="reg-pen.html#cb85-3"></a> ncomp.pls</span>
<span id="cb85-4"><a href="reg-pen.html#cb85-4"></a> [<span class="dv">1</span>] <span class="dv">7</span></span>
<span id="cb85-5"><a href="reg-pen.html#cb85-5"></a> prev.pls &lt;-<span class="st"> </span><span class="kw">predict</span>(pls.fit,<span class="dt">newdata=</span>S25,<span class="dt">ncomp=</span>ncomp.pls)</span></code></pre></div>
<div class="corR">
<ul>
<li>
<p>On trace les signaux :</p>
</li>
</ul>
</div>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="reg-pen.html#cb86-1"></a> signal1<span class="op">$</span>pcr &lt;-<span class="st"> </span>prev.pcr</span>
<span id="cb86-2"><a href="reg-pen.html#cb86-2"></a> signal1<span class="op">$</span>pls &lt;-<span class="st"> </span>prev.pls</span>
<span id="cb86-3"><a href="reg-pen.html#cb86-3"></a> signal2 &lt;-<span class="st"> </span>signal1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="op">-</span>x,<span class="dt">names_to=</span><span class="st">&quot;meth&quot;</span>,<span class="dt">values_to=</span><span class="st">&quot;y&quot;</span>)</span>
<span id="cb86-4"><a href="reg-pen.html#cb86-4"></a> <span class="kw">ggplot</span>(signal2)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>meth))<span class="op">+</span></span>
<span id="cb86-5"><a href="reg-pen.html#cb86-5"></a><span class="st">   </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>))<span class="op">+</span><span class="kw">geom_point</span>(<span class="dt">data=</span>donnees,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-133-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
On peut également obtenir les erreurs quadratiques (puisqu’on connait la vraie courbe)
</p>
</div></li>
</ol>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="reg-pen.html#cb87-1"></a>signal1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise_at</span>(<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>),<span class="op">~</span><span class="kw">mean</span>((.<span class="op">-</span>signal)<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb87-2"><a href="reg-pen.html#cb87-2"></a><span class="st">  </span><span class="kw">sort</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">3</span>)</span>
<span id="cb87-3"><a href="reg-pen.html#cb87-3"></a><span class="co"># A tibble: 1 x 4</span></span>
<span id="cb87-4"><a href="reg-pen.html#cb87-4"></a>  lasso   pls   pcr   MCO</span>
<span id="cb87-5"><a href="reg-pen.html#cb87-5"></a>  <span class="op">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span></span>
<span id="cb87-6"><a href="reg-pen.html#cb87-6"></a><span class="dv">1</span> <span class="fl">0.014</span> <span class="fl">0.055</span> <span class="fl">0.152</span>  <span class="fl">598.</span></span></code></pre></div>
</div>
<div id="régression-logistique-pénalisée" class="section level2">
<h2><span class="header-section-number">3.3</span> Régression logistique pénalisée</h2>
<p>On considère le jeu de données sur la détection d’images publicitaires disponible ici <a href="https://archive.ics.uci.edu/ml/datasets/internet+advertisements">https://archive.ics.uci.edu/ml/datasets/internet+advertisements</a>.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="reg-pen.html#cb88-1"></a>ad.data &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ad_data.txt&quot;</span>,<span class="dt">header=</span><span class="ot">FALSE</span>,<span class="dt">sep=</span><span class="st">&quot;,&quot;</span>,<span class="dt">dec=</span><span class="st">&quot;.&quot;</span>,<span class="dt">na.strings =</span> <span class="st">&quot;?&quot;</span>,<span class="dt">strip.white =</span> <span class="ot">TRUE</span>)</span>
<span id="cb88-2"><a href="reg-pen.html#cb88-2"></a><span class="kw">names</span>(ad.data)[<span class="kw">ncol</span>(ad.data)] &lt;-<span class="st"> &quot;Y&quot;</span></span>
<span id="cb88-3"><a href="reg-pen.html#cb88-3"></a>ad.data<span class="op">$</span>Y &lt;-<span class="st"> </span><span class="kw">as.factor</span>(ad.data<span class="op">$</span>Y)</span></code></pre></div>
<p>La variable à expliquer est</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="reg-pen.html#cb89-1"></a><span class="kw">summary</span>(ad.data<span class="op">$</span>Y)</span>
<span id="cb89-2"><a href="reg-pen.html#cb89-2"></a>   ad. nonad. </span>
<span id="cb89-3"><a href="reg-pen.html#cb89-3"></a>   <span class="dv">459</span>   <span class="dv">2820</span> </span></code></pre></div>
<p>Cette variable est binaire. On considère une régression logistique pour expliquer cette variable. Le nombre de variables explicatives étant important, comparer les algorithmes du maximum de vraisemblance aux algorithmes de type <strong>ridge/lasso</strong> en faisant une validation croisée 10 blocs.On pourra utiliser comme critère de comparaison l’<code>erreur de classification</code>, la <code>courbe ROC</code> et l’<code>AUC</code>. Il faudra également prendre des décisions pertinentes vis-à-vis des données manquantes…</p>
<div class="corR">
<p>
On commence par regarder les données manquantes :
</p>
</div>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="reg-pen.html#cb90-1"></a><span class="kw">sum</span>(<span class="kw">is.na</span>(ad.data))</span>
<span id="cb90-2"><a href="reg-pen.html#cb90-2"></a>[<span class="dv">1</span>] <span class="dv">2729</span></span>
<span id="cb90-3"><a href="reg-pen.html#cb90-3"></a>var.na &lt;-<span class="st"> </span><span class="kw">apply</span>(<span class="kw">is.na</span>(ad.data),<span class="dv">2</span>,any)</span>
<span id="cb90-4"><a href="reg-pen.html#cb90-4"></a><span class="kw">names</span>(ad.data)[var.na]</span>
<span id="cb90-5"><a href="reg-pen.html#cb90-5"></a>[<span class="dv">1</span>] <span class="st">&quot;V1&quot;</span> <span class="st">&quot;V2&quot;</span> <span class="st">&quot;V3&quot;</span> <span class="st">&quot;V4&quot;</span></span>
<span id="cb90-6"><a href="reg-pen.html#cb90-6"></a>ind.na &lt;-<span class="st"> </span><span class="kw">apply</span>(<span class="kw">is.na</span>(ad.data),<span class="dv">1</span>,any)</span>
<span id="cb90-7"><a href="reg-pen.html#cb90-7"></a><span class="kw">sum</span>(ind.na)</span>
<span id="cb90-8"><a href="reg-pen.html#cb90-8"></a>[<span class="dv">1</span>] <span class="dv">920</span></span></code></pre></div>
<div class="corR">
<p>
On remarque que 920 individus ont au moins une donnée manquante alors que seules les 4 premières variables ont des données manquantes, on choisit donc de supprimer ces 4 variables.
</p>
</div>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="reg-pen.html#cb91-1"></a>ad.data1 &lt;-<span class="st"> </span>ad.data[,var.na<span class="op">==</span><span class="ot">FALSE</span>]</span>
<span id="cb91-2"><a href="reg-pen.html#cb91-2"></a><span class="kw">dim</span>(ad.data1)</span>
<span id="cb91-3"><a href="reg-pen.html#cb91-3"></a>[<span class="dv">1</span>] <span class="dv">3279</span> <span class="dv">1555</span></span>
<span id="cb91-4"><a href="reg-pen.html#cb91-4"></a><span class="kw">sum</span>(<span class="kw">is.na</span>(ad.data1))</span>
<span id="cb91-5"><a href="reg-pen.html#cb91-5"></a>[<span class="dv">1</span>] <span class="dv">0</span></span></code></pre></div>
<p>On construit les matrices des variables explicatives pour les méthodes lasso et ridge (<code>glmnet</code> veut les variables explicatives sous forme de matrices).</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="reg-pen.html#cb92-1"></a>X.ad &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>ad.data1)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb92-2"><a href="reg-pen.html#cb92-2"></a>Y.ad &lt;-<span class="st"> </span>ad.data1<span class="op">$</span>Y</span></code></pre></div>
<p>Avant de faire la validation croisée, nous présentons juste comment faire l’algorithme <code>lasso</code>. Comme pour la régression, on utilise la fonction <code>cv.glmnet</code>, il faut juste ajouter l’argument <code>family="binomial"</code> :</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="reg-pen.html#cb93-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb93-2"><a href="reg-pen.html#cb93-2"></a>lasso.cv &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(X.ad,Y.ad,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb93-3"><a href="reg-pen.html#cb93-3"></a><span class="kw">plot</span>(lasso.cv)</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/lasso-ad-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
Par défaut le critère utilisé pour la classification binaire est celui de la <code>déviance</code>. On peut utilisé d’autres critères comme l’<code>erreur de classification</code> ou l’<code>auc</code> en modifiant l’argument <code>type.measure</code>. On gardera la déviance dans la suite. On peut maintenant faire la validation croisée 10 blocs pour calculer les prévisions des 3 algorithmes.
</p>
</div>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="reg-pen.html#cb94-1"></a><span class="kw">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb94-2"><a href="reg-pen.html#cb94-2"></a>blocs &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">createFolds</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(ad.data1),<span class="dt">k=</span><span class="dv">10</span>)</span>
<span id="cb94-3"><a href="reg-pen.html#cb94-3"></a>score &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">ncol=</span><span class="dv">3</span>,<span class="dt">nrow=</span><span class="kw">nrow</span>(ad.data1)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb94-4"><a href="reg-pen.html#cb94-4"></a><span class="kw">names</span>(score) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MV&quot;</span>,<span class="st">&quot;ridge&quot;</span>,<span class="st">&quot;lasso&quot;</span>)</span>
<span id="cb94-5"><a href="reg-pen.html#cb94-5"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){</span>
<span id="cb94-6"><a href="reg-pen.html#cb94-6"></a>  <span class="kw">print</span>(k)</span>
<span id="cb94-7"><a href="reg-pen.html#cb94-7"></a>  app &lt;-<span class="st"> </span>ad.data1[<span class="op">-</span>blocs[[k]],]</span>
<span id="cb94-8"><a href="reg-pen.html#cb94-8"></a>  test &lt;-<span class="st"> </span>ad.data1[blocs[[k]],]</span>
<span id="cb94-9"><a href="reg-pen.html#cb94-9"></a>  app.X &lt;-<span class="st"> </span>X.ad[<span class="op">-</span>blocs[[k]],]</span>
<span id="cb94-10"><a href="reg-pen.html#cb94-10"></a>  app.Y &lt;-<span class="st"> </span>Y.ad[<span class="op">-</span>blocs[[k]]]</span>
<span id="cb94-11"><a href="reg-pen.html#cb94-11"></a>  test.X &lt;-<span class="st"> </span>X.ad[blocs[[k]],]</span>
<span id="cb94-12"><a href="reg-pen.html#cb94-12"></a>  test.Y &lt;-<span class="st"> </span>Y.ad[blocs[[k]]]</span>
<span id="cb94-13"><a href="reg-pen.html#cb94-13"></a>  ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(app.X,app.Y,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>,<span class="dt">alpha=</span><span class="dv">0</span>)</span>
<span id="cb94-14"><a href="reg-pen.html#cb94-14"></a>  lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(app.X,app.Y,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>,<span class="dt">alpha=</span><span class="dv">1</span>)</span>
<span id="cb94-15"><a href="reg-pen.html#cb94-15"></a>  MV &lt;-<span class="st"> </span><span class="kw">glm</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>app,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb94-16"><a href="reg-pen.html#cb94-16"></a>  score[blocs[[k]],] &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">MV=</span><span class="kw">predict</span>(MV,<span class="dt">newdata=</span>test,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>),</span>
<span id="cb94-17"><a href="reg-pen.html#cb94-17"></a>             <span class="dt">ridge=</span><span class="kw">as.vector</span>(<span class="kw">predict</span>(ridge,<span class="dt">newx=</span>test.X,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)),</span>
<span id="cb94-18"><a href="reg-pen.html#cb94-18"></a>             <span class="dt">lasso=</span><span class="kw">as.vector</span>(<span class="kw">predict</span>(lasso,<span class="dt">newx=</span>test.X,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)))</span>
<span id="cb94-19"><a href="reg-pen.html#cb94-19"></a>}</span></code></pre></div>
<div class="corR">
<p>
Le <code>tibble score</code> contient, pour chaque individu, les prévisions eds probabilités a posteriori <span class="math display"><span class="math display">\[\prob(Y=\text{nonad.}|X=x_i),\quad i=1,\dots,n.\]</span></span>
</p>
<p>
On peut déduire de ce tableau les critères souhaités :
</p>
<ul>
<li>
les <code>courbes ROC</code>:
</li>
</ul>
</div>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="reg-pen.html#cb95-1"></a>score1 &lt;-<span class="st"> </span>score <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb95-2"><a href="reg-pen.html#cb95-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">obs=</span><span class="kw">fct_recode</span>(ad.data1<span class="op">$</span>Y,<span class="st">&quot;0&quot;</span>=<span class="st">&quot;ad.&quot;</span>,<span class="st">&quot;1&quot;</span>=<span class="st">&quot;nonad.&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb95-3"><a href="reg-pen.html#cb95-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>obs,<span class="dt">names_to=</span><span class="st">&quot;Methode&quot;</span>,<span class="dt">values_to=</span><span class="st">&quot;score&quot;</span>)</span>
<span id="cb95-4"><a href="reg-pen.html#cb95-4"></a><span class="kw">ggplot</span>(score1)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">m=</span>score,<span class="dt">d=</span><span class="kw">as.numeric</span>(obs),<span class="dt">color=</span>Methode)<span class="op">+</span>plotROC<span class="op">::</span><span class="kw">geom_roc</span>()</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-147-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<ul>
<li>
les <code>AUC</code>:
</li>
</ul>
</div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="reg-pen.html#cb96-1"></a>score1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Methode) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb96-2"><a href="reg-pen.html#cb96-2"></a><span class="st">      </span><span class="kw">summarize</span>(<span class="dt">AUC=</span><span class="kw">round</span>(<span class="kw">as.numeric</span>(pROC<span class="op">::</span><span class="kw">auc</span>(obs,score)),<span class="dv">3</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb96-3"><a href="reg-pen.html#cb96-3"></a><span class="st">      </span><span class="kw">arrange</span>(<span class="kw">desc</span>(AUC)) </span>
<span id="cb96-4"><a href="reg-pen.html#cb96-4"></a><span class="co"># A tibble: 3 x 2</span></span>
<span id="cb96-5"><a href="reg-pen.html#cb96-5"></a>  Methode   AUC</span>
<span id="cb96-6"><a href="reg-pen.html#cb96-6"></a>  <span class="op">&lt;</span>chr<span class="op">&gt;</span><span class="st">   </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span></span>
<span id="cb96-7"><a href="reg-pen.html#cb96-7"></a><span class="dv">1</span> ridge   <span class="fl">0.981</span></span>
<span id="cb96-8"><a href="reg-pen.html#cb96-8"></a><span class="dv">2</span> lasso   <span class="fl">0.945</span></span>
<span id="cb96-9"><a href="reg-pen.html#cb96-9"></a><span class="dv">3</span> MV      <span class="fl">0.756</span></span></code></pre></div>
<div class="corR">
<ul>
<li>
les <code>erreurs de classification</code> :
</li>
</ul>
</div>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="reg-pen.html#cb97-1"></a>score1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">prev=</span><span class="kw">round</span>(score),<span class="dt">err=</span>prev<span class="op">!=</span>obs) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb97-2"><a href="reg-pen.html#cb97-2"></a><span class="st">  </span><span class="kw">group_by</span>(Methode) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">Err_classif=</span><span class="kw">round</span>(<span class="kw">mean</span>(err),<span class="dv">3</span>)) <span class="op">%&gt;%</span></span>
<span id="cb97-3"><a href="reg-pen.html#cb97-3"></a><span class="st">  </span><span class="kw">arrange</span>(Err_classif) </span>
<span id="cb97-4"><a href="reg-pen.html#cb97-4"></a><span class="co"># A tibble: 3 x 2</span></span>
<span id="cb97-5"><a href="reg-pen.html#cb97-5"></a>  Methode Err_classif</span>
<span id="cb97-6"><a href="reg-pen.html#cb97-6"></a>  <span class="op">&lt;</span>chr<span class="op">&gt;</span><span class="st">         </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span></span>
<span id="cb97-7"><a href="reg-pen.html#cb97-7"></a><span class="dv">1</span> lasso         <span class="fl">0.03</span> </span>
<span id="cb97-8"><a href="reg-pen.html#cb97-8"></a><span class="dv">2</span> ridge         <span class="fl">0.03</span> </span>
<span id="cb97-9"><a href="reg-pen.html#cb97-9"></a><span class="dv">3</span> MV            <span class="fl">0.153</span></span></code></pre></div>
<div class="corR">
<p>
On remarque que les méthodes pénalisées sont nettement meilleures que l’approche classique par maximum de vraisemblance sur cet exemple.
</p>
</div>
</div>
<div id="exo-ridgelasso" class="section level2">
<h2><span class="header-section-number">3.4</span> Exercices</h2>

<div class="exercise">
<span id="exr:calcridge" class="exercise"><strong>Exercice 3.1  (Estimateurs ridge pour le modèle linéaire)  </strong></span>
</div>

<p>On considère le modèle de régression
<span class="math display">\[Y_i=\beta_1x_{i1}+\dots+\beta_px_{ip}+\varepsilon_i\]</span>
où les <span class="math inline">\(\varepsilon_i\)</span> sont i.i.d de loi <span class="math inline">\(\mathcal N(0,\sigma^2)\)</span>.
Pour <span class="math inline">\(\lambda\geq 0\)</span>, on note <span class="math inline">\(\hat\beta_R(\lambda)\)</span> l’estimateur ridge défini par
<span class="math display">\[\hat\beta_R(\lambda)=\mathop{\mathrm{argmin}}_\beta\sum_{i=1}^n\left(y_i-\sum_{j=1}^px_{ij}\beta_j\right)^2+\lambda\sum_{j=1}^p\beta_j^2.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Exprimer <span class="math inline">\(\hat\beta_R(\lambda)\)</span> en fonction de <span class="math inline">\(\mathbb X\)</span>, <span class="math inline">\(\mathbb Y\)</span> et <span class="math inline">\(\lambda\)</span>.</p>
<div class="correction">
<p>
Le critère à minimiser se réécrit <span class="math display"><span class="math display">\[\mathcal C(\beta)=(\mathbb Y-\mathbb X\beta)^t (\mathbb Y-\mathbb X\beta)+\lambda\beta^t\beta.\]</span></span> L’estimateur ridge est donc solution de <span class="math display"><span class="math display">\[-2\mathbb X^t\mathbb Y+2\mathbb X^t\mathbb X\beta+2\lambda\beta=0,\]</span></span> d’où <span class="math display"><span class="math display">\[\hat\beta_R(\lambda)=(\mathbb X^t\mathbb X+\lambda I)^{-1}\mathbb X^t\mathbb Y.\]</span></span>
</p>
</div></li>
<li><p>Étudier le biais et la variance de <span class="math inline">\(\hat\beta_R(\lambda)\)</span> en fonction de <span class="math inline">\(\lambda\)</span>. On pourra également faire la comparaison avec l’estimateurs de MCO.</p>
<div class="correction">
<p>
Comme <span class="math inline"><span class="math inline">\(\mathbb Y=\mathbb X\beta+\varepsilon\)</span></span>, on obtient <span class="math display"><span class="math display">\[\begin{align*}
 \mathbf E[\hat\beta_R(\lambda)]-\beta &amp;=(\mathbb X^t\mathbb X+\lambda I)^{-1}\mathbb X^t\mathbb X\beta-\beta \\
 &amp;=\left[(\mathbb X^t\mathbb X+\lambda I)^{-1}(\mathbb X^t\mathbb X-(\mathbb X^t\mathbb X+\lambda I))\right]\beta \\
 &amp;= -\lambda(\mathbb X^t\mathbb X+\lambda I)^{-1}\beta.
 \end{align*}\]</span></span> De même, on obtient pour la variance <span class="math display"><span class="math display">\[\mathbf V(\hat\beta_R(\lambda))=\sigma^2(\mathbb X^t\mathbb X+\lambda\mathbb I)^{-1}\mathbb X^t\mathbb X(\mathbb X^t\mathbb X+\lambda\mathbb I)^{-1}.\]</span></span> La variance diminue lorsque <span class="math inline"><span class="math inline">\(\lambda\)</span></span> augmente, mais on remarque une augmentation du bais par rapport à l’estimateur des moindres carrés (et réciproquement lorsque <span class="math inline"><span class="math inline">\(\lambda\)</span></span> diminue).
</p>
</div></li>
<li><p>On suppose que la matrice <span class="math inline">\(\mathbb X\)</span> est orthogonale. Exprimer les estimateurs <span class="math inline">\(\hat\beta_{R,j}(\lambda)\)</span> en fonction des estimateurs des MCO <span class="math inline">\(\hat\beta_j, j=1,\dots,p\)</span>. Interpréter.</p>
<div class="correction">
<p>
Si <span class="math inline"><span class="math inline">\(\mathbb X\)</span></span> est orthogonale, alors <span class="math display"><span class="math display">\[\hat\beta_R(\lambda)=\frac{1}{1+\lambda}\mathbb X^t\mathbb Y=\frac{\hat\beta_{MCO}}{1+\lambda}.\]</span></span>
</p>
</div></li>
</ol>

<div class="exercise">
<span id="exr:calclasso" class="exercise"><strong>Exercice 3.2  (Estimateurs lasso dans le cas orthogonal,voir <span class="citation">Giraud (<a href="#ref-gir15" role="doc-biblioref">2015</a>)</span>)  </strong></span>
</div>

<p>On rappelle qu’une fonction <span class="math inline">\(F:\mathbb R^n\to\mathbb R\)</span> est convexe si <span class="math inline">\(\forall x,y\in\mathbb R^n\)</span>, <span class="math inline">\(\forall\lambda\in[0,1]\)</span> on a
<span class="math display">\[F(\lambda x+(1-\lambda) y)\leq \lambda F(x)+(1-\lambda)F(y).\]</span>
On définit la sous-différentielle d’une fonction convexe <span class="math inline">\(F\)</span> par
<span class="math display">\[\partial F(x)=\{w\in\mathbb R^n:F(y)\geq F(x)+\langle w,y-x\rangle\textrm{ pour tout }y\in\mathbb R^n\}.\]</span>
On admettra que les minima d’une fonction convexe <span class="math inline">\(F:\mathbb R^n\to\mathbb R\)</span> sont caractérisés par
<span class="math display">\[x^\star\in\mathop{\mathrm{argmin}}_{x\in\mathbb R^n}F(x)\Longleftrightarrow 0\in \partial F(x^\star)\]</span>
et que <span class="math inline">\(\partial F(x)=\{\nabla F(x)\}\)</span> lorsque <span class="math inline">\(F\)</span> est différentiable en <span class="math inline">\(x\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Montrer que pour <span class="math inline">\(x\in\mathbb R\)</span>
<span class="math display">\[\partial |x|=\left\{
  \begin{array}{ll}
 \textrm{signe}(x)   &amp; \textrm{si } x\neq 0 \\
\left[-1;1\right] &amp; \textrm{sinon,}
  \end{array}\right.\]</span>
où <span class="math inline">\(\text{signe}(x)=\mathbf 1_{x&gt;0}-\mathbf 1_{x\leq 0}\)</span>.
<div class="correction">
<p>
<span class="math inline"><span class="math inline">\(x\mapsto|x|\)</span></span> est dérivable partout sauf en 0 donc <span class="math inline"><span class="math inline">\(\partial |x|=\textrm{signe}(x)1\)</span></span> si <span class="math inline"><span class="math inline">\(x\neq 0\)</span></span>. De plus, si <span class="math inline"><span class="math inline">\(x=0\)</span></span> <span class="math display"><span class="math display">\[\partial|x|=\{w\in\mathbb R:|y|\geq \langle w,y\rangle\ \forall y\in\mathbb R\}=\{w\in\mathbb R:|y|\geq wy\ \forall y\in\mathbb R\}=[-1,1].\]</span></span>
</p>
</div></li>
<li>Soit <span class="math inline">\(x\in\mathbb R^n\)</span>.
<ol style="list-style-type: lower-alpha">
<li>Montrer que
<span class="math display">\[\partial\|x\|_1=\{w\in\mathbb R^n:\langle w,x\rangle=\|x\|_1\text{ et }\|w\|_\infty\leq 1\}.\]</span>
On pourra utiliser que pour tout <span class="math inline">\(p,q\)</span> tels que <span class="math inline">\(1/p+1/q=1\)</span> on a
<span class="math display">\[\|x\|_p=\sup\left\{\langle w,x\rangle:\|w\|_q\leq 1\right\}.\]</span>
<div class="correction">
<p>
On montre la double inclusion. Soit <span class="math inline"><span class="math inline">\(w\)</span></span> tel que <span class="math inline"><span class="math inline">\(\langle w,x\rangle=\|x\|_1\)</span></span> et <span class="math inline"><span class="math inline">\(\|w\|_\infty=1\)</span></span>. On a <span class="math inline"><span class="math inline">\(\forall y\in\mathbb R^n\)</span></span> : <span class="math display"><span class="math display">\[\|y\|_1\geq \langle w,y\rangle=\langle w,y-x+x\rangle=\|x\|_1+\langle w,y-x\rangle.\]</span></span> Donc <span class="math inline"><span class="math inline">\(w\in\partial\|x\|_1\)</span></span>. Inversement, soit <span class="math inline"><span class="math inline">\(w\in\partial\|x\|_1\)</span></span>. Par définition <span class="math display"><span class="math display">\[\partial\|x\|_1=\{w\in\mathbb R^n:\|y\|_1\geq \langle w,y-x\rangle+\|x\|_1\ \forall y\in\mathbb R^n\}.\]</span></span> Pour <span class="math inline"><span class="math inline">\(y=0\)</span></span> et <span class="math inline"><span class="math inline">\(y=2x\)</span></span>, on a donc <span class="math display"><span class="math display">\[\|x\|_1\leq\langle w,x\rangle\quad\textrm{et}\quad 2\|x\|_1\geq \langle w,x\rangle+\|x\|_1\]</span></span> d’où <span class="math inline"><span class="math inline">\(\|x\|_1=\langle x,w\rangle=\sum_iw_ix_i\)</span></span>. De plus en posant <span class="math inline"><span class="math inline">\(\tilde w=(0,\dots,0,\text{signe}(w_i),0,\dots,0)\)</span></span> où la coordonnée non nulle correspond au <span class="math inline"><span class="math inline">\(\max_i(|w_i|)\)</span></span> on a <span class="math inline"><span class="math inline">\(\|w\|_\infty=\langle w,\tilde w\rangle\)</span></span> et <span class="math inline"><span class="math inline">\(\|\tilde w\|_\infty=\|\tilde w\|_1=1\)</span></span>. De plus <span class="math display"><span class="math display">\[\|\tilde w\|_1\geq \|x\|_1+\langle w,\tilde{w}-x\rangle=\|w\|_\infty\quad\Longrightarrow \|w\|_\infty\leq \|\tilde w\|_1=1.\]</span></span>
</p>
</div></li>
<li>En déduire
<span class="math display">\[\partial\|x\|_1=\{w\in\mathbb R^n:w_j=\textrm{signe}(x_j)\textrm{ si }x_j\neq 0, w_j\in[-1,1]\textrm{ si }x_j=0\}.\]</span>
<div class="correction">
<p>
On a <span class="math display"><span class="math display">\[\begin{align*}
 \partial\|x\|_1 &amp;=\{w\in\mathbb R^n:\langle w,x\rangle=\|x\|_1\text{ et }\|w\|_\infty\leq 1\}\\
 &amp;= \{w\in\mathbb R^n:\sum_{i=1}^n(w_ix_i-|x_i|)=0\text{ et }\|w\|_\infty\leq 1\}.
 \end{align*}\]</span></span> Or si <span class="math inline"><span class="math inline">\(\|w\|_\infty\leq 1\)</span></span> alors <span class="math inline"><span class="math inline">\(w_ix_i-|x_i|\leq 0\)</span></span> <span class="math inline"><span class="math inline">\(\forall i=1,\dots,n\)</span></span>. Donc <span class="math display"><span class="math display">\[\begin{align*}
 \partial\|x\|_1 &amp;=\{w\in\mathbb R^n:(w_ix_i-|x_i|)=0,i=1,\dots,n\text{ et }\|w\|_\infty\leq 1\}\\
 &amp;=\{w\in\mathbb R^n:w_j=\textrm{signe}(x_j)1\textrm{ si }x_j\neq 0, w_j\in[-1,1]\textrm{ si }x_j=0\}.
 \end{align*}\]</span></span>
</p>
</div></li>
</ol></li>
<li>Étant données <span class="math inline">\(n\)</span> observations <span class="math inline">\((x_i,y_i),i=1,\dots,n\)</span> telles que <span class="math inline">\(x_i\in\mathbb R^p\)</span> et <span class="math inline">\(y_i\in\mathbb R\)</span> on rappelle que l’estimateur lasso <span class="math inline">\(\hat\beta(\lambda)\)</span> est construit en minimisant
<span class="math display" id="eq:critL1">\[\begin{equation}
  \mathcal L(\beta)=\|Y-\mathbb X\beta\|_2^2+\lambda\|\beta\|_1.  
  \tag{3.2}
  \end{equation}\]</span>
On admettra que la sous-différentielle <span class="math inline">\(\partial \mathcal L(\beta)\)</span> est donnée par
<span class="math display">\[\partial \mathcal L(\beta)=\left\{-2\mathbb X^t(Y-\mathbb X\beta)+\lambda z:z\in\partial\|\beta\|_1\right\}.\]</span>
Montrer que <span class="math inline">\(\hat\beta(\lambda)\)</span> vérifie
<span class="math display">\[\mathbb X^t\mathbb X\hat\beta(\lambda)=\mathbb X^tY-\frac{\lambda}{2}\hat z\]</span>
où <span class="math inline">\(\hat z\in\mathbb R^p\)</span> vérifie
<span class="math display">\[\hat z_j\left\{
  \begin{array}{ll}
 =\textrm{signe}(\hat\beta_j(\lambda))   &amp; \textrm{si } \hat\beta_j(\lambda)\neq 0 \\
\in\left[-1;1\right] &amp; \textrm{sinon.}
  \end{array}\right.\]</span>
<div class="correction">
<p>
D’après les indications, on a <span class="math inline"><span class="math inline">\(0\in\partial \mathcal L(\hat\beta(\lambda))\)</span></span>. Donc il existe <span class="math inline"><span class="math inline">\(\hat z\in\partial\|\hat\beta(\lambda)\|_1\)</span></span> tel que <span class="math display"><span class="math display">\[-2\mathbb X^t(Y-\mathbb X\hat\beta(\lambda))+\lambda \hat z=0\quad\Longleftrightarrow\quad \mathbb X^t\mathbb X\hat\beta(\lambda)=\mathbb X^tY-\frac{\lambda}{2}\hat z.\]</span></span>
</p>
</div></li>
<li>On suppose maintenant que la matrice <span class="math inline">\(\mathbb X\)</span> est orthogonale.
<ol style="list-style-type: lower-alpha">
<li>Montrer que
<span class="math display">\[\textrm{signe}(\hat\beta_j(\lambda))=\textrm{signe}(\mathbb X_j^tY)\quad\textrm{lorsque }\hat\beta_j(\lambda)\neq 0\]</span>
et <span class="math inline">\(\hat\beta_j(\lambda)=0\)</span> si et seulement si <span class="math inline">\(|\mathbb X_j^tY|\leq \lambda/2\)</span>.
<div class="correction">
<p>
<span class="math inline"><span class="math inline">\(\mathbb X\)</span></span> étant orthogonale, on a pour <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)\neq 0\)</span></span> <span class="math display"><span class="math display">\[\hat\beta_j(\lambda)+\frac{\lambda}{2}\textrm{signe}(\hat\beta_j(\lambda))=\hat\beta_j(\lambda)\left(1+\frac{\lambda}{2|\hat\beta_j(\lambda)|}\right)=\mathbb X_j^tY,\]</span></span> donc <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)\)</span></span> est du signe de <span class="math inline"><span class="math inline">\(\mathbb X_j^tY\)</span></span>. De plus :
</p>
<ul>
<li>
si <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)=0\)</span></span> alors <span class="math inline"><span class="math inline">\(\mathbb X^t_jY=\frac{\lambda}{2}\hat z_j\)</span></span> avec <span class="math inline"><span class="math inline">\(\hat z_j\in[-1,1]\)</span></span>. Donc <span class="math display"><span class="math display">\[|\mathbb X^t_jY|=\left|\frac{\lambda}{2}\hat z_j\right|\leq\frac{\lambda}{2}.\]</span></span>
</li>
<li>
si <span class="math inline"><span class="math inline">\(|\mathbb X_j^tY|\leq \lambda/2\)</span></span> et si <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)\neq 0\)</span></span> alors <span class="math display"><span class="math display">\[\left|\hat\beta_j(\lambda)\left(1+\frac{\lambda}{2|\hat\beta_j(\lambda)|}\right)\right|=|\hat\beta_j(\lambda)|+\frac{\lambda}{2}=|\mathbb X^t_jY|\leq\frac{\lambda}{2}.\]</span></span>
</li>
</ul>
<p>
Donc <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)=0\)</span></span>.
</p>
</div></li>
<li>En déduire
<span class="math display">\[\hat\beta_j(\lambda)=\mathbb X_j^tY\left(1-\frac{\lambda}{2|\mathbb X_j^tY|}\right)_+,\quad j=1,\dots,p\]</span>
où <span class="math inline">\((x)_+=\max(x,0)\)</span>. Interpréter ce résultat.
<div class="correction">
<p>
On obtient donc <span class="math display"><span class="math display">\[\hat\beta_j(\lambda)=\mathbb X_j^tY-\frac{\lambda}{2}\,\frac{\mathbb X_j^tY}{|\mathbb X_j^tY|}=\mathbb X_j^tY\left(1-\frac{\lambda}{2|\mathbb X_j^tY|}\right)\]</span></span> si <span class="math inline"><span class="math inline">\(\mathbb X_j^tY\geq \frac{\lambda}{2}\)</span></span> et <span class="math inline"><span class="math inline">\(\hat\beta_j(\lambda)=0\)</span></span> sinon. D’où <span class="math display"><span class="math display">\[\hat\beta_j(\lambda)=\mathbb X_j^tY\left(1-\frac{\lambda}{2|\mathbb X_j^tY|}\right)_+,\quad j=1,\dots,d.\]</span></span>
</p>
</div></li>
</ol></li>
</ol>

<div class="exercise">
<span id="exr:unicite-lasso" class="exercise"><strong>Exercice 3.3  (Unicité de l’estimateur lasso,voir <span class="citation">Giraud (<a href="#ref-gir15" role="doc-biblioref">2015</a>)</span>)  </strong></span>
</div>

<p>Soit <span class="math inline">\(\hat\beta^{1}(\lambda)\)</span> et <span class="math inline">\(\hat\beta^{2}(\lambda)\)</span> deux solutions qui minimisent <a href="reg-pen.html#eq:critL1">(3.2)</a>. Soit <span class="math inline">\(\hat\beta=(\hat\beta^{1}(\lambda)+\hat\beta^{2}(\lambda))/2\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Montrer que si <span class="math inline">\(\mathbb X \hat\beta^{1}(\lambda)\neq\mathbb X \hat\beta^{2}(\lambda)\)</span> alors
<span class="math display">\[\|\mathbb Y-\mathbb X\hat\beta\|_2^2+\lambda\|\hat\beta\|_1&lt;\frac{1}{2}\left(\|\mathbb Y-\mathbb X\hat\beta^1(\lambda)\|_2^2+\lambda\|\hat\beta^1(\lambda)\|_1+\|\mathbb Y-\mathbb X\hat\beta^2(\lambda)\|_2^2+\lambda\|\hat\beta^2(\lambda)\|_1\right).\]</span>
On pourra utiliser la convexité (forte) de <span class="math inline">\(x\mapsto\|x\|_2^2\)</span>.</p>
<div class="correction">
<p>
On a <span class="math display"><span class="math display">\[\begin{align*}
 \|\mathbb Y-\mathbb X\hat\beta\|_2^2+\lambda\|\hat\beta\|_1= &amp;\left\|\frac{1}{2}(\mathbb Y-\mathbb X\hat\beta^1(\lambda))+\frac{1}{2}(\mathbb Y-\mathbb X\hat\beta^2(\lambda))\right\|_2^2+\lambda\left\|\frac{1}{2}(\hat\beta^1(\lambda)+\hat\beta^2(\lambda))\right\|_1 \\
 &lt;&amp;\frac{1}{2}\left\|\mathbb Y-\mathbb X\hat\beta^1(\lambda))\right\|_2^2+\frac{1}{2}\left\|\mathbb Y-\mathbb X\hat\beta^2(\lambda))\right\|_2^2+\frac{1}{2}\lambda\|\hat\beta^1(\lambda)\|_1+\frac{1}{2}\lambda\|\hat\beta^2(\lambda)\|_1
 \end{align*}\]</span></span> en utilisant la stricte convexité de <span class="math inline"><span class="math inline">\(x\mapsto\|x\|_2^2\)</span></span> et l’inégalité triangulaire.
</p>
</div></li>
<li><p>En déduire que <span class="math inline">\(\mathbb X \hat\beta^{1}(\lambda)=\mathbb X \hat\beta^{2}(\lambda)\)</span>.</p>
<div class="correction">
<p>
Donc si <span class="math inline"><span class="math inline">\(\mathbb X \hat\beta^{1}(\lambda)\neq\mathbb X \hat\beta^{2}(\lambda)\)</span></span> alors <span class="math display"><span class="math display">\[\|\mathbb Y-\mathbb X\hat\beta\|_2^2+\lambda\|\hat\beta\|_1&lt;\|\mathbb Y-\mathbb X\hat\beta^1(\lambda)\|_2^2+\lambda\|\hat\beta^1(\lambda)\|_1\]</span></span> ce qui est impossible par définition de <span class="math inline"><span class="math inline">\(\hat\beta^1(\lambda)\)</span></span>.
</p>
</div></li>
</ol>

</div>
</div>
<h3>Références</h3>
<div id="refs" class="references">
<div id="ref-gir15">
<p>Giraud, C. 2015. <em>Introduction to High-Dimensional Statistics</em>. CRC Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reg-comp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mod-add.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TUTO_GRANDE_DIM.pdf", "TUTO_GRANDE_DIM.epub"],
"toc": {
"collapse": "subsection",
"fontsettings": {
"theme": "white",
"size": 2,
"family": "sans"
},
"sharing": {
"facebook": true,
"github": true,
"twitter": true
}
},
"highlight": "default"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
