<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension</title>
  <meta name="description" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 3 Régressions pénalisées (ou sous contraintes) | Régression en grande dimension" />
  
  
  

<meta name="author" content="Laurent Rouvière" />


<meta name="date" content="2020-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reg-comp.html"/>
<link rel="next" href="mod-add.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Régression en grande dimension<br> <br> L. Rouvière</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Présentation</a></li>
<li class="chapter" data-level="1" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html"><i class="fa fa-check"></i><b>1</b> Introduction à la grande dimension</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#fléau-de-la-dimension-pour-les-plus-proches-voisins"><i class="fa fa-check"></i><b>1.1</b> Fléau de la dimension pour les plus proches voisins</a></li>
<li class="chapter" data-level="1.2" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#influence-de-la-dimension-dans-le-modèle-linéaire"><i class="fa fa-check"></i><b>1.2</b> Influence de la dimension dans le modèle linéaire</a></li>
<li class="chapter" data-level="1.3" data-path="intro-grande-dim.html"><a href="intro-grande-dim.html#exercices"><i class="fa fa-check"></i><b>1.3</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reg-comp.html"><a href="reg-comp.html"><i class="fa fa-check"></i><b>2</b> Régression sur composantes</a><ul>
<li class="chapter" data-level="2.1" data-path="reg-comp.html"><a href="reg-comp.html#sélection-de-variables"><i class="fa fa-check"></i><b>2.1</b> Sélection de variables</a></li>
<li class="chapter" data-level="2.2" data-path="reg-comp.html"><a href="reg-comp.html#régression-sur-composantes-principales-méthodo"><i class="fa fa-check"></i><b>2.2</b> Régression sur composantes principales (méthodo)</a></li>
<li class="chapter" data-level="2.3" data-path="reg-comp.html"><a href="reg-comp.html#régression-pls-méthodo"><i class="fa fa-check"></i><b>2.3</b> Régression PLS : méthodo</a></li>
<li class="chapter" data-level="2.4" data-path="reg-comp.html"><a href="reg-comp.html#comparaison-pcr-vs-pls."><i class="fa fa-check"></i><b>2.4</b> Comparaison : PCR vs PLS.</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reg-pen.html"><a href="reg-pen.html"><i class="fa fa-check"></i><b>3</b> Régressions pénalisées (ou sous contraintes)</a><ul>
<li class="chapter" data-level="3.1" data-path="reg-pen.html"><a href="reg-pen.html#ridge-et-lasso-avec-glmnet"><i class="fa fa-check"></i><b>3.1</b> Ridge et lasso avec glmnet</a></li>
<li class="chapter" data-level="3.2" data-path="reg-pen.html"><a href="reg-pen.html#reconstruction-dun-signal"><i class="fa fa-check"></i><b>3.2</b> Reconstruction d’un signal</a></li>
<li class="chapter" data-level="3.3" data-path="reg-pen.html"><a href="reg-pen.html#régression-logistique-pénalisée"><i class="fa fa-check"></i><b>3.3</b> Régression logistique pénalisée</a></li>
<li class="chapter" data-level="3.4" data-path="reg-pen.html"><a href="reg-pen.html#exo-ridgelasso"><i class="fa fa-check"></i><b>3.4</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mod-add.html"><a href="mod-add.html"><i class="fa fa-check"></i><b>4</b> Modèle additif</a><ul>
<li class="chapter" data-level="4.1" data-path="mod-add.html"><a href="mod-add.html#pseudo-backfitting"><i class="fa fa-check"></i><b>4.1</b> Pseudo backfitting</a></li>
<li class="chapter" data-level="4.2" data-path="mod-add.html"><a href="mod-add.html#modèle-gam"><i class="fa fa-check"></i><b>4.2</b> Modèle GAM</a></li>
<li class="chapter" data-level="4.3" data-path="mod-add.html"><a href="mod-add.html#régression-logistique-additive"><i class="fa fa-check"></i><b>4.3</b> Régression logistique additive</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Régression en grande dimension</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg-pen" class="section level1">
<h1><span class="header-section-number">Chapitre 3</span> Régressions pénalisées (ou sous contraintes)</h1>
<p>Nous considérons toujours le modèle linéaire</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X_1+\dots+\beta_dX_d+\varepsilon\]</span>
Lorsque <span class="math inline">\(d\)</span> est grand ou que les variables sont linéairement dépendantes, les estimateurs des moindres carrées peuvent être mis en défaut. Les méthodes pénalisées ou sous contraintes consistent alors à restreindre l’espace sur lequel on minimise ce critère. On va alors chercher le vecteur <span class="math inline">\(\beta\)</span> qui minimise</p>
<p><span class="math display">\[\sum_{i=1}^n \left(y_i-\beta_0-\sum_{j=1}^dx_{ij}\beta_j\right)^2\quad\text{sous la contrainte }\quad\sum_{j=1}^d\beta_j^2\leq t\]</span>
ou de façon équivalente (dans le sens où il existe une équivalence entre <span class="math inline">\(t\)</span> et <span class="math inline">\(\lambda\)</span>)</p>
<p><span class="math display">\[\sum_{i=1}^n \left(y_i-\beta_0-\sum_{j=1}^dx_{ij}\beta_j\right)^2+\lambda\sum_{j=1}^d\beta_j^2.\]</span>
Les estimateurs obtenus sont les estimateurs <strong>ridge</strong>. Les estimateurs <strong>lasso</strong> s’obtiennent en remplaçant la contrainte ou la pénalité par une norme 1 (<span class="math inline">\(\sum_{j=1}^d|\beta_j|\)</span>). Nous présentons dans cette partie les étapes principales qui permettent de faire ce type de régression avec <strong>R</strong>. Le package le plus souvent utilisé est <code>glmnet</code>.</p>
<div id="ridge-et-lasso-avec-glmnet" class="section level2">
<h2><span class="header-section-number">3.1</span> Ridge et lasso avec glmnet</h2>
<p>On considère le jeu de données <code>ozone.txt</code> où on cherche à expliquer la concentration maximale en ozone relevée sur une journée (variable <code>maxO3</code>) par d’autres variables essentiellement météorologiques.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="reg-pen.html#cb13-1"></a>ozone &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ozone.txt&quot;</span>)</span>
<span id="cb13-2"><a href="reg-pen.html#cb13-2"></a><span class="kw">head</span>(ozone)</span>
<span id="cb13-3"><a href="reg-pen.html#cb13-3"></a>         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12</span>
<span id="cb13-4"><a href="reg-pen.html#cb13-4"></a><span class="dv">20010601</span>    <span class="dv">87</span> <span class="fl">15.6</span> <span class="fl">18.5</span> <span class="fl">18.4</span>   <span class="dv">4</span>    <span class="dv">4</span>    <span class="dv">8</span>  <span class="fl">0.6946</span> <span class="fl">-1.7101</span></span>
<span id="cb13-5"><a href="reg-pen.html#cb13-5"></a><span class="dv">20010602</span>    <span class="dv">82</span> <span class="fl">17.0</span> <span class="fl">18.4</span> <span class="fl">17.7</span>   <span class="dv">5</span>    <span class="dv">5</span>    <span class="dv">7</span> <span class="fl">-4.3301</span> <span class="fl">-4.0000</span></span>
<span id="cb13-6"><a href="reg-pen.html#cb13-6"></a><span class="dv">20010603</span>    <span class="dv">92</span> <span class="fl">15.3</span> <span class="fl">17.6</span> <span class="fl">19.5</span>   <span class="dv">2</span>    <span class="dv">5</span>    <span class="dv">4</span>  <span class="fl">2.9544</span>  <span class="fl">1.8794</span></span>
<span id="cb13-7"><a href="reg-pen.html#cb13-7"></a><span class="dv">20010604</span>   <span class="dv">114</span> <span class="fl">16.2</span> <span class="fl">19.7</span> <span class="fl">22.5</span>   <span class="dv">1</span>    <span class="dv">1</span>    <span class="dv">0</span>  <span class="fl">0.9848</span>  <span class="fl">0.3473</span></span>
<span id="cb13-8"><a href="reg-pen.html#cb13-8"></a><span class="dv">20010605</span>    <span class="dv">94</span> <span class="fl">17.4</span> <span class="fl">20.5</span> <span class="fl">20.4</span>   <span class="dv">8</span>    <span class="dv">8</span>    <span class="dv">7</span> <span class="fl">-0.5000</span> <span class="fl">-2.9544</span></span>
<span id="cb13-9"><a href="reg-pen.html#cb13-9"></a><span class="dv">20010606</span>    <span class="dv">80</span> <span class="fl">17.7</span> <span class="fl">19.8</span> <span class="fl">18.3</span>   <span class="dv">6</span>    <span class="dv">6</span>    <span class="dv">7</span> <span class="fl">-5.6382</span> <span class="fl">-5.0000</span></span>
<span id="cb13-10"><a href="reg-pen.html#cb13-10"></a>            Vx15 maxO3v  vent pluie</span>
<span id="cb13-11"><a href="reg-pen.html#cb13-11"></a><span class="dv">20010601</span> <span class="fl">-0.6946</span>     <span class="dv">84</span>  Nord   Sec</span>
<span id="cb13-12"><a href="reg-pen.html#cb13-12"></a><span class="dv">20010602</span> <span class="fl">-3.0000</span>     <span class="dv">87</span>  Nord   Sec</span>
<span id="cb13-13"><a href="reg-pen.html#cb13-13"></a><span class="dv">20010603</span>  <span class="fl">0.5209</span>     <span class="dv">82</span>   Est   Sec</span>
<span id="cb13-14"><a href="reg-pen.html#cb13-14"></a><span class="dv">20010604</span> <span class="fl">-0.1736</span>     <span class="dv">92</span>  Nord   Sec</span>
<span id="cb13-15"><a href="reg-pen.html#cb13-15"></a><span class="dv">20010605</span> <span class="fl">-4.3301</span>    <span class="dv">114</span> Ouest   Sec</span>
<span id="cb13-16"><a href="reg-pen.html#cb13-16"></a><span class="dv">20010606</span> <span class="fl">-6.0000</span>     <span class="dv">94</span> Ouest Pluie</span></code></pre></div>
<p>Contrairement à la plupart des autres package <strong>R</strong> qui permettent de faire de l’apprentissage, le package <code>glmnet</code> n’autorise pas l’utilisation de <code>formules</code> : il faut spécifier explicitement la matrice des <span class="math inline">\(X\)</span> et le vecteur des <span class="math inline">\(Y\)</span>. On peut obtenir la matrice des <span class="math inline">\(X\)</span> et notamment le codage des variables qualitatives avec la fonction <code>model.matrix</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="reg-pen.html#cb14-1"></a>ozone.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(maxO3<span class="op">~</span>.,<span class="dt">data=</span>ozone)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb14-2"><a href="reg-pen.html#cb14-2"></a>ozone.Y &lt;-<span class="st"> </span>ozone<span class="op">$</span>maxO3</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Charger le package <code>glmnet</code> et à l’aide de la fonction <code>glmnet</code> calculer les estimateurs <code>ridge</code> et <code>lasso</code>.</p></li>
<li><p>Analyser les sorties qui se trouvent dans les arguments <code>lambda</code> et <code>beta</code> de <code>glmnet</code>.</p></li>
<li><p>Visualiser les chemins de régularisation des estimateurs <code>ridge</code> et <code>lasso</code>. On pourra utiliser la fonction <code>plot</code>.</p></li>
<li><p>Sélectionner les paramètres de régularisation à l’aide de la fonction <code>cv.glmnet</code>. On pourra notamment faire un <code>plot</code> de l’objet et expliquer le graphe obtenu.</p></li>
<li><p>On souhaite prédire la variable cible pour de nouveaux individus, par exemple les 25ème et 50ème individus du jeu de données. Calculer les valeurs prédites pour ces deux individus.</p></li>
<li><p>A l’aide d’une validation croisée, comparer les performances des estimateurs <strong>MCO</strong>, <strong>ridge</strong> et <strong>lasso</strong>. On pourra utiliser les données <code>ozone_complet.txt</code> qui contiennent plus d’individus et de variables.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="reg-pen.html#cb15-1"></a>ozone1 &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ozone_complet.txt&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;;&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">na.omit</span>()</span>
<span id="cb15-2"><a href="reg-pen.html#cb15-2"></a>ozone1.X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(maxO3<span class="op">~</span>.,<span class="dt">data=</span>ozone1)[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb15-3"><a href="reg-pen.html#cb15-3"></a>ozone1.Y &lt;-<span class="st"> </span>ozone1<span class="op">$</span>maxO3</span></code></pre></div></li>
<li><p>Refaire la question précédente en considérant toutes les interactions d’ordre 2.</p></li>
</ol>
</div>
<div id="reconstruction-dun-signal" class="section level2">
<h2><span class="header-section-number">3.2</span> Reconstruction d’un signal</h2>
<p>Le fichier <code>signal.csv</code> contient un signal que l’on peut représenter par une fonction <span class="math inline">\(m:\mathbb R\to\mathbb R\)</span>. On le visualise</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="reg-pen.html#cb16-1"></a>signal &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/signal.csv&quot;</span>)</span>
<span id="cb16-2"><a href="reg-pen.html#cb16-2"></a><span class="kw">ggplot</span>(signal)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>()</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-116-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Plaçons nous dans le cas où on ne dispose que d’une version bruitée de ce signal. La courbe n’est pas observée mais on dispose d’un échantillon <span class="math inline">\((x_i,y_i),i=1,\dots,n\)</span> généré selon le modèle</p>
<p><span class="math display">\[y_i=m(x_i)+\varepsilon_i.\]</span></p>
<p>Le fichier <code>ech_signal.csv</code> contient <span class="math inline">\(n=60\)</span> observations issues de ce modèle. On représente les données et la courbe</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="reg-pen.html#cb17-1"></a>donnees &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/ech_signal.csv&quot;</span>)</span>
<span id="cb17-2"><a href="reg-pen.html#cb17-2"></a><span class="kw">ggplot</span>(signal)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y)<span class="op">+</span><span class="kw">geom_line</span>()<span class="op">+</span></span>
<span id="cb17-3"><a href="reg-pen.html#cb17-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>donnees,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))</span></code></pre></div>
<p><img src="TUTO_GRANDE_DIM_files/figure-html/unnamed-chunk-117-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Nous cherchons dans cette partie à reconstruire le signal à partir de l’échantillon. Bien entendu, vu la forme du signal, un modèle linéaire de la forme
<span class="math display">\[y_i=\beta_0+\beta_1x_i+\varepsilon_i\]</span>
n’est pas approprié. De nombreuses approches en <strong>traitement du signal</strong> proposent d’utiliser une <code>base</code> ou <code>dictionnaire</code> représentée par une collection de fonctions <span class="math inline">\(\{\psi_j(x)\}_{j=1,\dots,K}\)</span> et de décomposer le signal dans cette base :</p>
<p><span class="math display">\[m(x)\approx \sum_{j=1}^K \beta_j\psi_j(x).\]</span></p>
<p>Pour un dictionnaire donné, on peut alors considérer un <strong>modèle linéaire</strong></p>
<p><span class="math display" id="eq:mod-lin-signal">\[\begin{equation}
  y_i=\sum_{j=1}^K \beta_j\psi_j(x)+\varepsilon_i.
  \tag{3.1}
\end{equation}\]</span></p>
<p>Le problème est toujours d’estimer les paramètres <span class="math inline">\(\beta_j\)</span> mais les variables sont maintenant définies par les élements du dictionnaire. Il existe différents types de dictionnaire, dans cet exercice nous proposons de considérer la base de Fourier définie par</p>
<p><span class="math display">\[\psi_0(x)=1,\quad \psi_{2j-1}(x)=\cos(2j\pi x)\quad\text{et}\quad \psi_{2j}(x)=\sin(2j\pi x),\quad j=1,\dots,K.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Écrire une fonction <strong>R</strong> qui admet en entrée :</p>
<ul>
<li>une grille de valeurs de <code>x</code> (un vecteur)</li>
<li>une valeur de <code>K</code> (un entier positif)</li>
</ul>
<p>et qui renvoie en sortie une matrice qui contiennent les valeurs du dictionnaire pour chaque valeur de <code>x</code>. Cette matrice devra donc contenir <code>2K</code> colonnes et le nombre de lignes sera égal à la longueur du vecteur <code>x</code>.</p></li>
<li><p>On fixe <code>K=25</code>. Calculer les estimateurs des moindres carrés du modèle <a href="reg-pen.html#eq:mod-lin-signal">(3.1)</a>.</p></li>
<li><p>Représenter le signal estimé. Commenter le graphe.</p></li>
<li><p>Calculer les estimateurs <strong>lasso</strong> et représenter le signal issu de ces estimateurs.</p></li>
<li><p>Identifier les coefficients lasso sélectionnés qui ne sont pas nuls.</p></li>
<li><p>Ajouter les signaux ajustés par les algorithme PCR et PLS.</p></li>
</ol>
</div>
<div id="régression-logistique-pénalisée" class="section level2">
<h2><span class="header-section-number">3.3</span> Régression logistique pénalisée</h2>
<p>On considère le jeu de données sur la détection d’images publicitaires disponible ici <a href="https://archive.ics.uci.edu/ml/datasets/internet+advertisements">https://archive.ics.uci.edu/ml/datasets/internet+advertisements</a>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="reg-pen.html#cb18-1"></a>ad.data &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/ad_data.txt&quot;</span>,<span class="dt">header=</span><span class="ot">FALSE</span>,<span class="dt">sep=</span><span class="st">&quot;,&quot;</span>,<span class="dt">dec=</span><span class="st">&quot;.&quot;</span>,<span class="dt">na.strings =</span> <span class="st">&quot;?&quot;</span>,<span class="dt">strip.white =</span> <span class="ot">TRUE</span>)</span>
<span id="cb18-2"><a href="reg-pen.html#cb18-2"></a><span class="kw">names</span>(ad.data)[<span class="kw">ncol</span>(ad.data)] &lt;-<span class="st"> &quot;Y&quot;</span></span>
<span id="cb18-3"><a href="reg-pen.html#cb18-3"></a>ad.data<span class="op">$</span>Y &lt;-<span class="st"> </span><span class="kw">as.factor</span>(ad.data<span class="op">$</span>Y)</span></code></pre></div>
<p>La variable à expliquer est</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="reg-pen.html#cb19-1"></a><span class="kw">summary</span>(ad.data<span class="op">$</span>Y)</span>
<span id="cb19-2"><a href="reg-pen.html#cb19-2"></a>   ad. nonad. </span>
<span id="cb19-3"><a href="reg-pen.html#cb19-3"></a>   <span class="dv">459</span>   <span class="dv">2820</span> </span></code></pre></div>
<p>Cette variable est binaire. On considère une régression logistique pour expliquer cette variable. Le nombre de variables explicatives étant important, comparer les algorithmes du maximum de vraisemblance aux algorithmes de type <strong>ridge/lasso</strong> en faisant une validation croisée 10 blocs. On pourra utiliser comme critère de comparaison l’<code>erreur de classification</code>, la <code>courbe ROC</code> et l’<code>AUC</code>. Il faudra également prendre des décisions pertinentes vis-à-vis des données manquantes…</p>
</div>
<div id="exo-ridgelasso" class="section level2">
<h2><span class="header-section-number">3.4</span> Exercices</h2>

<div class="exercise">
<span id="exr:calcridge" class="exercise"><strong>Exercice 3.1  (Estimateurs ridge pour le modèle linéaire)  </strong></span>
</div>

<p>On considère le modèle de régression
<span class="math display">\[Y_i=\beta_1x_{i1}+\dots+\beta_px_{ip}+\varepsilon_i\]</span>
où les <span class="math inline">\(\varepsilon_i\)</span> sont i.i.d de loi <span class="math inline">\(\mathcal N(0,\sigma^2)\)</span>.
Pour <span class="math inline">\(\lambda\geq 0\)</span>, on note <span class="math inline">\(\hat\beta_R(\lambda)\)</span> l’estimateur ridge défini par
<span class="math display">\[\hat\beta_R(\lambda)=\mathop{\mathrm{argmin}}_\beta\sum_{i=1}^n\left(y_i-\sum_{j=1}^px_{ij}\beta_j\right)^2+\lambda\sum_{j=1}^p\beta_j^2.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Exprimer <span class="math inline">\(\hat\beta_R(\lambda)\)</span> en fonction de <span class="math inline">\(\mathbb X\)</span>, <span class="math inline">\(\mathbb Y\)</span> et <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>Étudier le biais et la variance de <span class="math inline">\(\hat\beta_R(\lambda)\)</span> en fonction de <span class="math inline">\(\lambda\)</span>. On pourra également faire la comparaison avec l’estimateur des MCO.</p></li>
<li><p>On suppose que la matrice <span class="math inline">\(\mathbb X\)</span> est orthogonale. Exprimer les estimateurs <span class="math inline">\(\hat\beta_{R,j}(\lambda)\)</span> en fonction des estimateurs des MCO <span class="math inline">\(\hat\beta_j, j=1,\dots,p\)</span>. Interpréter.</p></li>
</ol>

<div class="exercise">
<span id="exr:calclasso" class="exercise"><strong>Exercice 3.2  (Estimateurs lasso dans le cas orthogonal,voir <span class="citation">Giraud (<a href="#ref-gir15" role="doc-biblioref">2015</a>)</span>)  </strong></span>
</div>

<p>On rappelle qu’une fonction <span class="math inline">\(F:\mathbb R^n\to\mathbb R\)</span> est convexe si <span class="math inline">\(\forall x,y\in\mathbb R^n\)</span>, <span class="math inline">\(\forall\lambda\in[0,1]\)</span> on a
<span class="math display">\[F(\lambda x+(1-\lambda) y)\leq \lambda F(x)+(1-\lambda)F(y).\]</span>
On définit la sous-différentielle d’une fonction convexe <span class="math inline">\(F\)</span> par
<span class="math display">\[\partial F(x)=\{w\in\mathbb R^n:F(y)\geq F(x)+\langle w,y-x\rangle\textrm{ pour tout }y\in\mathbb R^n\}.\]</span>
On admettra que les minima d’une fonction convexe <span class="math inline">\(F:\mathbb R^n\to\mathbb R\)</span> sont caractérisés par
<span class="math display">\[x^\star\in\mathop{\mathrm{argmin}}_{x\in\mathbb R^n}F(x)\Longleftrightarrow 0\in \partial F(x^\star)\]</span>
et que <span class="math inline">\(\partial F(x)=\{\nabla F(x)\}\)</span> lorsque <span class="math inline">\(F\)</span> est différentiable en <span class="math inline">\(x\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Montrer que pour <span class="math inline">\(x\in\mathbb R\)</span>
<span class="math display">\[
\partial |x|=\left\{
\begin{array}{ll}
\textrm{signe}(x)   &amp; \textrm{si } x\neq 0 \\
\left[-1;1\right] &amp; \textrm{sinon,}
\end{array}\right.
\]</span>
où <span class="math inline">\(\text{signe}(x)=\mathbf 1_{x&gt;0}-\mathbf 1_{x\leq 0}\)</span>.</p></li>
<li><p>Soit <span class="math inline">\(x\in\mathbb R^n\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Montrer que
<span class="math display">\[\partial\|x\|_1=\{w\in\mathbb R^n:\langle w,x\rangle=\|x\|_1\text{ et }\|w\|_\infty\leq 1\}.\]</span>
On pourra utiliser que pour tout <span class="math inline">\(p,q\)</span> tels que <span class="math inline">\(1/p+1/q=1\)</span> on a
<span class="math display">\[\|x\|_p=\sup\left\{\langle w,x\rangle:\|w\|_q\leq 1\right\}.\]</span></p></li>
<li><p>En déduire
<span class="math display">\[\partial\|x\|_1=\{w\in\mathbb R^n:w_j=\textrm{signe}(x_j)\textrm{ si }x_j\neq 0, w_j\in[-1,1]\textrm{ si }x_j=0\}.\]</span></p></li>
</ol></li>
<li><p>Étant données <span class="math inline">\(n\)</span> observations <span class="math inline">\((x_i,y_i),i=1,\dots,n\)</span> telles que <span class="math inline">\(x_i\in\mathbb R^p\)</span> et <span class="math inline">\(y_i\in\mathbb R\)</span> on rappelle que l’estimateur lasso <span class="math inline">\(\hat\beta(\lambda)\)</span> est construit en minimisant
<span class="math display" id="eq:critL1">\[\begin{equation}
  \mathcal L(\beta)=\|Y-\mathbb X\beta\|_2^2+\lambda\|\beta\|_1.  
  \tag{3.2}
  \end{equation}\]</span>
On admettra que la sous-différentielle <span class="math inline">\(\partial \mathcal L(\beta)\)</span> est donnée par
<span class="math display">\[\partial \mathcal L(\beta)=\left\{-2\mathbb X^t(Y-\mathbb X\beta)+\lambda z:z\in\partial\|\beta\|_1\right\}.\]</span>
Montrer que <span class="math inline">\(\hat\beta(\lambda)\)</span> vérifie
<span class="math display">\[\mathbb X^t\mathbb X\hat\beta(\lambda)=\mathbb X^tY-\frac{\lambda}{2}\hat z\]</span>
où <span class="math inline">\(\hat z\in\mathbb R^p\)</span> vérifie
<span class="math display">\[\hat z_j\left\{
  \begin{array}{ll}
 =\textrm{signe}(\hat\beta_j(\lambda))   &amp; \textrm{si } \hat\beta_j(\lambda)\neq 0 \\
\in\left[-1;1\right] &amp; \textrm{sinon.}
  \end{array}\right.\]</span></p></li>
<li><p>On suppose maintenant que la matrice <span class="math inline">\(\mathbb X\)</span> est orthogonale.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Montrer que
<span class="math display">\[\textrm{signe}(\hat\beta_j(\lambda))=\textrm{signe}(\mathbb X_j^tY)\quad\textrm{lorsque }\hat\beta_j(\lambda)\neq 0\]</span>
et <span class="math inline">\(\hat\beta_j(\lambda)=0\)</span> si et seulement si <span class="math inline">\(|\mathbb X_j^tY|\leq \lambda/2\)</span>.</p></li>
<li><p>En déduire
<span class="math display">\[\hat\beta_j(\lambda)=\mathbb X_j^tY\left(1-\frac{\lambda}{2|\mathbb X_j^tY|}\right)_+,\quad j=1,\dots,p\]</span>
où <span class="math inline">\((x)_+=\max(x,0)\)</span>. Interpréter ce résultat.</p></li>
</ol></li>
</ol>

<div class="exercise">
<span id="exr:unicite-lasso" class="exercise"><strong>Exercice 3.3  (Unicité de l’estimateur lasso,voir <span class="citation">Giraud (<a href="#ref-gir15" role="doc-biblioref">2015</a>)</span>)  </strong></span>
</div>

<p>Soit <span class="math inline">\(\hat\beta^{1}(\lambda)\)</span> et <span class="math inline">\(\hat\beta^{2}(\lambda)\)</span> deux solutions qui minimisent <a href="reg-pen.html#eq:critL1">(3.2)</a>. Soit <span class="math inline">\(\hat\beta=(\hat\beta^{1}(\lambda)+\hat\beta^{2}(\lambda))/2\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Montrer que si <span class="math inline">\(\mathbb X \hat\beta^{1}(\lambda)\neq\mathbb X \hat\beta^{2}(\lambda)\)</span> alors
<span class="math display">\[\|\mathbb Y-\mathbb X\hat\beta\|_2^2+\lambda\|\hat\beta\|_1&lt;\frac{1}{2}\left(\|\mathbb Y-\mathbb X\hat\beta^1(\lambda)\|_2^2+\lambda\|\hat\beta^1(\lambda)\|_1+\|\mathbb Y-\mathbb X\hat\beta^2(\lambda)\|_2^2+\lambda\|\hat\beta^2(\lambda)\|_1\right).\]</span>
On pourra utiliser la convexité (forte) de <span class="math inline">\(x\mapsto\|x\|_2^2\)</span>.</p></li>
<li><p>En déduire que <span class="math inline">\(\mathbb X \hat\beta^{1}(\lambda)=\mathbb X \hat\beta^{2}(\lambda)\)</span>.</p></li>
</ol>

</div>
</div>
<h3>Références</h3>
<div id="refs" class="references">
<div id="ref-gir15">
<p>Giraud, C. 2015. <em>Introduction to High-Dimensional Statistics</em>. CRC Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reg-comp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mod-add.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TUTO_GRANDE_DIM.pdf"],
"toc": {
"collapse": "subsection",
"fontsettings": {
"theme": "white",
"size": 2,
"family": "sans"
},
"sharing": {
"facebook": true,
"github": true,
"twitter": true
}
},
"highlight": "default"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
